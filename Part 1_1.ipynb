{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "RHvtKZuJGgSi",
    "outputId": "00207d97-1424-424c-e449-4d6b3ee36678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Colab has two versions of TensorFlow installed: a 1.x version and a 2.x version. \n",
    "# Colab currently uses TF 1.x by default\n",
    "# To enable TF2 execute the following code\n",
    "\n",
    "# %tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "n7tSvt4EEeNz",
    "outputId": "fb7dba56-0ab7-4e36-8f79-680f7416aa84",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w shape ==> (10, 784)\n",
      "tr_x shape ==> (60000, 784)\n",
      "Iteration  0 :Train Loss : 2.5799365  Train Accuracy:  0.89999664\n",
      "            : Test Loss :2.446585178375244 Test Accuracy : 0.8999999761581421 \n",
      "****************************************************************************************************\n",
      "Iteration  1 :Train Loss : 2.4462223  Train Accuracy:  0.9\n",
      "            : Test Loss :2.332047462463379 Test Accuracy : 0.8999999761581421 \n",
      "****************************************************************************************************\n",
      "Iteration  2 :Train Loss : 2.3314688  Train Accuracy:  0.9\n",
      "            : Test Loss :2.2336478233337402 Test Accuracy : 0.8999999761581421 \n",
      "****************************************************************************************************\n",
      "Iteration  3 :Train Loss : 2.2327018  Train Accuracy:  0.9\n",
      "            : Test Loss :2.147242307662964 Test Accuracy : 0.8999999761581421 \n",
      "****************************************************************************************************\n",
      "Iteration  4 :Train Loss : 2.1458168  Train Accuracy:  0.9\n",
      "            : Test Loss :2.0681228637695312 Test Accuracy : 0.8999999761581421 \n",
      "****************************************************************************************************\n",
      "Iteration  5 :Train Loss : 2.0661318  Train Accuracy:  0.9\n",
      "            : Test Loss :1.9927743673324585 Test Accuracy : 0.8999999761581421 \n",
      "****************************************************************************************************\n",
      "Iteration  6 :Train Loss : 1.9901601  Train Accuracy:  0.9\n",
      "            : Test Loss :1.9200396537780762 Test Accuracy : 0.8999999761581421 \n",
      "****************************************************************************************************\n",
      "Iteration  7 :Train Loss : 1.9167669  Train Accuracy:  0.90000165\n",
      "            : Test Loss :1.8504149913787842 Test Accuracy : 0.8999999761581421 \n",
      "****************************************************************************************************\n",
      "Iteration  8 :Train Loss : 1.8464671  Train Accuracy:  0.90000665\n",
      "            : Test Loss :1.7849185466766357 Test Accuracy : 0.9000300168991089 \n",
      "****************************************************************************************************\n",
      "Iteration  9 :Train Loss : 1.780293  Train Accuracy:  0.900025\n",
      "            : Test Loss :1.7243062257766724 Test Accuracy : 0.9001200199127197 \n",
      "****************************************************************************************************\n",
      "Iteration  10 :Train Loss : 1.719014  Train Accuracy:  0.900085\n",
      "            : Test Loss :1.6687171459197998 Test Accuracy : 0.9002699851989746 \n",
      "****************************************************************************************************\n",
      "Iteration  11 :Train Loss : 1.6627828  Train Accuracy:  0.90023\n",
      "            : Test Loss :1.6176726818084717 Test Accuracy : 0.9005600214004517 \n",
      "****************************************************************************************************\n",
      "Iteration  12 :Train Loss : 1.6111348  Train Accuracy:  0.900555\n",
      "            : Test Loss :1.5703372955322266 Test Accuracy : 0.9010800123214722 \n",
      "****************************************************************************************************\n",
      "Iteration  13 :Train Loss : 1.5632498  Train Accuracy:  0.9011383\n",
      "            : Test Loss :1.5258737802505493 Test Accuracy : 0.9024999737739563 \n",
      "****************************************************************************************************\n",
      "Iteration  14 :Train Loss : 1.5182996  Train Accuracy:  0.9023783\n",
      "            : Test Loss :1.4836982488632202 Test Accuracy : 0.9041399955749512 \n",
      "****************************************************************************************************\n",
      "Iteration  15 :Train Loss : 1.4757042  Train Accuracy:  0.90392834\n",
      "            : Test Loss :1.4435621500015259 Test Accuracy : 0.9056000113487244 \n",
      "****************************************************************************************************\n",
      "Iteration  16 :Train Loss : 1.4352138  Train Accuracy:  0.905625\n",
      "            : Test Loss :1.4054895639419556 Test Accuracy : 0.9073100090026855 \n",
      "****************************************************************************************************\n",
      "Iteration  17 :Train Loss : 1.3968443  Train Accuracy:  0.907425\n",
      "            : Test Loss :1.3696415424346924 Test Accuracy : 0.9090700149536133 \n",
      "****************************************************************************************************\n",
      "Iteration  18 :Train Loss : 1.3607459  Train Accuracy:  0.9092733\n",
      "            : Test Loss :1.3361769914627075 Test Accuracy : 0.9110599756240845 \n",
      "****************************************************************************************************\n",
      "Iteration  19 :Train Loss : 1.3270651  Train Accuracy:  0.91119\n",
      "            : Test Loss :1.3051515817642212 Test Accuracy : 0.9130200147628784 \n",
      "****************************************************************************************************\n",
      "Iteration  20 :Train Loss : 1.2958435  Train Accuracy:  0.91331834\n",
      "            : Test Loss :1.276472806930542 Test Accuracy : 0.9150500297546387 \n",
      "****************************************************************************************************\n",
      "Iteration  21 :Train Loss : 1.2669784  Train Accuracy:  0.915425\n",
      "            : Test Loss :1.2499241828918457 Test Accuracy : 0.9169999957084656 \n",
      "****************************************************************************************************\n",
      "Iteration  22 :Train Loss : 1.2402443  Train Accuracy:  0.9175367\n",
      "            : Test Loss :1.225233554840088 Test Accuracy : 0.9188799858093262 \n",
      "****************************************************************************************************\n",
      "Iteration  23 :Train Loss : 1.215362  Train Accuracy:  0.91940165\n",
      "            : Test Loss :1.202157735824585 Test Accuracy : 0.9205700159072876 \n",
      "****************************************************************************************************\n",
      "Iteration  24 :Train Loss : 1.1920844  Train Accuracy:  0.92119\n",
      "            : Test Loss :1.1805381774902344 Test Accuracy : 0.9225999712944031 \n",
      "****************************************************************************************************\n",
      "Iteration  25 :Train Loss : 1.1702517  Train Accuracy:  0.92288333\n",
      "            : Test Loss :1.1603049039840698 Test Accuracy : 0.9242799878120422 \n",
      "****************************************************************************************************\n",
      "Iteration  26 :Train Loss : 1.1497942  Train Accuracy:  0.92455167\n",
      "            : Test Loss :1.1414275169372559 Test Accuracy : 0.925570011138916 \n",
      "****************************************************************************************************\n",
      "Iteration  27 :Train Loss : 1.1306841  Train Accuracy:  0.92616165\n",
      "            : Test Loss :1.1238577365875244 Test Accuracy : 0.9269300103187561 \n",
      "****************************************************************************************************\n",
      "Iteration  28 :Train Loss : 1.1128768  Train Accuracy:  0.9276017\n",
      "            : Test Loss :1.1074906587600708 Test Accuracy : 0.9282600283622742 \n",
      "****************************************************************************************************\n",
      "Iteration  29 :Train Loss : 1.0962721  Train Accuracy:  0.92901164\n",
      "            : Test Loss :1.0921663045883179 Test Accuracy : 0.9293699860572815 \n",
      "****************************************************************************************************\n",
      "Iteration  30 :Train Loss : 1.0807163  Train Accuracy:  0.930355\n",
      "            : Test Loss :1.0777113437652588 Test Accuracy : 0.9305499792098999 \n",
      "****************************************************************************************************\n",
      "Iteration  31 :Train Loss : 1.0660394  Train Accuracy:  0.9314833\n",
      "            : Test Loss :1.0639857053756714 Test Accuracy : 0.9318699836730957 \n",
      "****************************************************************************************************\n",
      "Iteration  32 :Train Loss : 1.052104  Train Accuracy:  0.9326233\n",
      "            : Test Loss :1.0509127378463745 Test Accuracy : 0.9328600168228149 \n",
      "****************************************************************************************************\n",
      "Iteration  33 :Train Loss : 1.0388339  Train Accuracy:  0.93364334\n",
      "            : Test Loss :1.0384769439697266 Test Accuracy : 0.9338399767875671 \n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  34 :Train Loss : 1.0262125  Train Accuracy:  0.9345667\n",
      "            : Test Loss :1.0266954898834229 Test Accuracy : 0.9346100091934204 \n",
      "****************************************************************************************************\n",
      "Iteration  35 :Train Loss : 1.0142537  Train Accuracy:  0.9354867\n",
      "            : Test Loss :1.0155785083770752 Test Accuracy : 0.9354199767112732 \n",
      "****************************************************************************************************\n",
      "Iteration  36 :Train Loss : 1.0029652  Train Accuracy:  0.936295\n",
      "            : Test Loss :1.0051050186157227 Test Accuracy : 0.9361000061035156 \n",
      "****************************************************************************************************\n",
      "Iteration  37 :Train Loss : 0.99232286  Train Accuracy:  0.9370033\n",
      "            : Test Loss :0.9952197074890137 Test Accuracy : 0.9367899894714355 \n",
      "****************************************************************************************************\n",
      "Iteration  38 :Train Loss : 0.9822693  Train Accuracy:  0.93766165\n",
      "            : Test Loss :0.9858487248420715 Test Accuracy : 0.9375600218772888 \n",
      "****************************************************************************************************\n",
      "Iteration  39 :Train Loss : 0.97272986  Train Accuracy:  0.9382667\n",
      "            : Test Loss :0.9769256711006165 Test Accuracy : 0.9381099939346313 \n",
      "****************************************************************************************************\n",
      "Iteration  40 :Train Loss : 0.96363735  Train Accuracy:  0.93872166\n",
      "            : Test Loss :0.968406081199646 Test Accuracy : 0.938319981098175 \n",
      "****************************************************************************************************\n",
      "Iteration  41 :Train Loss : 0.9549477  Train Accuracy:  0.9392267\n",
      "            : Test Loss :0.960267961025238 Test Accuracy : 0.938730001449585 \n",
      "****************************************************************************************************\n",
      "Iteration  42 :Train Loss : 0.94663906  Train Accuracy:  0.93971664\n",
      "            : Test Loss :0.9525002241134644 Test Accuracy : 0.9392899870872498 \n",
      "****************************************************************************************************\n",
      "Iteration  43 :Train Loss : 0.9387016  Train Accuracy:  0.94009835\n",
      "            : Test Loss :0.9450867176055908 Test Accuracy : 0.9395700097084045 \n",
      "****************************************************************************************************\n",
      "Iteration  44 :Train Loss : 0.9311208  Train Accuracy:  0.9404467\n",
      "            : Test Loss :0.9379997849464417 Test Accuracy : 0.939740002155304 \n",
      "****************************************************************************************************\n",
      "Iteration  45 :Train Loss : 0.9238695  Train Accuracy:  0.94076836\n",
      "            : Test Loss :0.9312002062797546 Test Accuracy : 0.9401999711990356 \n",
      "****************************************************************************************************\n",
      "Iteration  46 :Train Loss : 0.91691107  Train Accuracy:  0.94108\n",
      "            : Test Loss :0.9246514439582825 Test Accuracy : 0.9405699968338013 \n",
      "****************************************************************************************************\n",
      "Iteration  47 :Train Loss : 0.9102097  Train Accuracy:  0.941435\n",
      "            : Test Loss :0.9183275103569031 Test Accuracy : 0.9408599734306335 \n",
      "****************************************************************************************************\n",
      "Iteration  48 :Train Loss : 0.90373945  Train Accuracy:  0.94171333\n",
      "            : Test Loss :0.912216305732727 Test Accuracy : 0.9411500096321106 \n",
      "****************************************************************************************************\n",
      "Iteration  49 :Train Loss : 0.89748824  Train Accuracy:  0.94201666\n",
      "            : Test Loss :0.9063146710395813 Test Accuracy : 0.9414299726486206 \n",
      "****************************************************************************************************\n",
      "Iteration  50 :Train Loss : 0.89145243  Train Accuracy:  0.94234\n",
      "            : Test Loss :0.9006208777427673 Test Accuracy : 0.9417999982833862 \n",
      "****************************************************************************************************\n",
      "Iteration  51 :Train Loss : 0.88562936  Train Accuracy:  0.94270164\n",
      "            : Test Loss :0.8951284885406494 Test Accuracy : 0.9421600103378296 \n",
      "****************************************************************************************************\n",
      "Iteration  52 :Train Loss : 0.8800113  Train Accuracy:  0.943\n",
      "            : Test Loss :0.8898249864578247 Test Accuracy : 0.942330002784729 \n",
      "****************************************************************************************************\n",
      "Iteration  53 :Train Loss : 0.87458503  Train Accuracy:  0.9432783\n",
      "            : Test Loss :0.8846943378448486 Test Accuracy : 0.9426000118255615 \n",
      "****************************************************************************************************\n",
      "Iteration  54 :Train Loss : 0.86933386  Train Accuracy:  0.943545\n",
      "            : Test Loss :0.8797220587730408 Test Accuracy : 0.942870020866394 \n",
      "****************************************************************************************************\n",
      "Iteration  55 :Train Loss : 0.8642432  Train Accuracy:  0.94380164\n",
      "            : Test Loss :0.8748974800109863 Test Accuracy : 0.9430800080299377 \n",
      "****************************************************************************************************\n",
      "Iteration  56 :Train Loss : 0.8593026  Train Accuracy:  0.9440783\n",
      "            : Test Loss :0.8702130913734436 Test Accuracy : 0.9433599710464478 \n",
      "****************************************************************************************************\n",
      "Iteration  57 :Train Loss : 0.85450506  Train Accuracy:  0.9443617\n",
      "            : Test Loss :0.8656625151634216 Test Accuracy : 0.943589985370636 \n",
      "****************************************************************************************************\n",
      "Iteration  58 :Train Loss : 0.84984493  Train Accuracy:  0.944605\n",
      "            : Test Loss :0.861237108707428 Test Accuracy : 0.943880021572113 \n",
      "****************************************************************************************************\n",
      "Iteration  59 :Train Loss : 0.84531486  Train Accuracy:  0.944805\n",
      "            : Test Loss :0.8569278120994568 Test Accuracy : 0.9439799785614014 \n",
      "****************************************************************************************************\n",
      "Iteration  60 :Train Loss : 0.8409055  Train Accuracy:  0.9450333\n",
      "            : Test Loss :0.8527247905731201 Test Accuracy : 0.944100022315979 \n",
      "****************************************************************************************************\n",
      "Iteration  61 :Train Loss : 0.8366077  Train Accuracy:  0.9452317\n",
      "            : Test Loss :0.8486208915710449 Test Accuracy : 0.9442700147628784 \n",
      "****************************************************************************************************\n",
      "Iteration  62 :Train Loss : 0.83241415  Train Accuracy:  0.945485\n",
      "            : Test Loss :0.8446127772331238 Test Accuracy : 0.9444400072097778 \n",
      "****************************************************************************************************\n",
      "Iteration  63 :Train Loss : 0.8283199  Train Accuracy:  0.94569665\n",
      "            : Test Loss :0.840699315071106 Test Accuracy : 0.9446899890899658 \n",
      "****************************************************************************************************\n",
      "Iteration  64 :Train Loss : 0.82432306  Train Accuracy:  0.94592834\n",
      "            : Test Loss :0.836880087852478 Test Accuracy : 0.944920003414154 \n",
      "****************************************************************************************************\n",
      "Iteration  65 :Train Loss : 0.8204211  Train Accuracy:  0.94613165\n",
      "            : Test Loss :0.8331536054611206 Test Accuracy : 0.945110023021698 \n",
      "****************************************************************************************************\n",
      "Iteration  66 :Train Loss : 0.8166108  Train Accuracy:  0.94631165\n",
      "            : Test Loss :0.829515814781189 Test Accuracy : 0.9452099800109863 \n",
      "****************************************************************************************************\n",
      "Iteration  67 :Train Loss : 0.8128874  Train Accuracy:  0.9464833\n",
      "            : Test Loss :0.8259627223014832 Test Accuracy : 0.9454299807548523 \n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  68 :Train Loss : 0.8092453  Train Accuracy:  0.94670665\n",
      "            : Test Loss :0.8224894404411316 Test Accuracy : 0.9455199837684631 \n",
      "****************************************************************************************************\n",
      "Iteration  69 :Train Loss : 0.80568093  Train Accuracy:  0.94689333\n",
      "            : Test Loss :0.8190925717353821 Test Accuracy : 0.9456800222396851 \n",
      "****************************************************************************************************\n",
      "Iteration  70 :Train Loss : 0.8021909  Train Accuracy:  0.9470533\n",
      "            : Test Loss :0.8157689571380615 Test Accuracy : 0.9458699822425842 \n",
      "****************************************************************************************************\n",
      "Iteration  71 :Train Loss : 0.7987733  Train Accuracy:  0.94726\n",
      "            : Test Loss :0.8125152587890625 Test Accuracy : 0.9460200071334839 \n",
      "****************************************************************************************************\n",
      "Iteration  72 :Train Loss : 0.79542613  Train Accuracy:  0.9474767\n",
      "            : Test Loss :0.8093268275260925 Test Accuracy : 0.9462400078773499 \n",
      "****************************************************************************************************\n",
      "Iteration  73 :Train Loss : 0.7921462  Train Accuracy:  0.94764835\n",
      "            : Test Loss :0.806199848651886 Test Accuracy : 0.946340024471283 \n",
      "****************************************************************************************************\n",
      "Iteration  74 :Train Loss : 0.7889301  Train Accuracy:  0.9478317\n",
      "            : Test Loss :0.8031302690505981 Test Accuracy : 0.9465399980545044 \n",
      "****************************************************************************************************\n",
      "Iteration  75 :Train Loss : 0.78577507  Train Accuracy:  0.9480283\n",
      "            : Test Loss :0.8001160025596619 Test Accuracy : 0.9467999935150146 \n",
      "****************************************************************************************************\n",
      "Iteration  76 :Train Loss : 0.7826782  Train Accuracy:  0.94825166\n",
      "            : Test Loss :0.7971556782722473 Test Accuracy : 0.9470499753952026 \n",
      "****************************************************************************************************\n",
      "Iteration  77 :Train Loss : 0.7796383  Train Accuracy:  0.9484583\n",
      "            : Test Loss :0.7942487597465515 Test Accuracy : 0.9472000002861023 \n",
      "****************************************************************************************************\n",
      "Iteration  78 :Train Loss : 0.7766539  Train Accuracy:  0.948635\n",
      "            : Test Loss :0.7913947105407715 Test Accuracy : 0.9473400115966797 \n",
      "****************************************************************************************************\n",
      "Iteration  79 :Train Loss : 0.7737237  Train Accuracy:  0.94882333\n",
      "            : Test Loss :0.7885921597480774 Test Accuracy : 0.9475799798965454 \n",
      "****************************************************************************************************\n",
      "Iteration  80 :Train Loss : 0.7708457  Train Accuracy:  0.94899833\n",
      "            : Test Loss :0.7858391404151917 Test Accuracy : 0.9477599859237671 \n",
      "****************************************************************************************************\n",
      "Iteration  81 :Train Loss : 0.7680179  Train Accuracy:  0.94917834\n",
      "            : Test Loss :0.7831336855888367 Test Accuracy : 0.9478999972343445 \n",
      "****************************************************************************************************\n",
      "Iteration  82 :Train Loss : 0.7652379  Train Accuracy:  0.9493667\n",
      "            : Test Loss :0.7804742455482483 Test Accuracy : 0.9479799866676331 \n",
      "****************************************************************************************************\n",
      "Iteration  83 :Train Loss : 0.7625044  Train Accuracy:  0.94952\n",
      "            : Test Loss :0.7778594493865967 Test Accuracy : 0.9481499791145325 \n",
      "****************************************************************************************************\n",
      "Iteration  84 :Train Loss : 0.7598163  Train Accuracy:  0.9497067\n",
      "            : Test Loss :0.7752884030342102 Test Accuracy : 0.9483799934387207 \n",
      "****************************************************************************************************\n",
      "Iteration  85 :Train Loss : 0.75717235  Train Accuracy:  0.94987\n",
      "            : Test Loss :0.7727594971656799 Test Accuracy : 0.9485099911689758 \n",
      "****************************************************************************************************\n",
      "Iteration  86 :Train Loss : 0.75457174  Train Accuracy:  0.95006835\n",
      "            : Test Loss :0.7702714800834656 Test Accuracy : 0.9486600160598755 \n",
      "****************************************************************************************************\n",
      "Iteration  87 :Train Loss : 0.7520129  Train Accuracy:  0.9502233\n",
      "            : Test Loss :0.7678230404853821 Test Accuracy : 0.9488400220870972 \n",
      "****************************************************************************************************\n",
      "Iteration  88 :Train Loss : 0.74949425  Train Accuracy:  0.95038\n",
      "            : Test Loss :0.7654125094413757 Test Accuracy : 0.9489499926567078 \n",
      "****************************************************************************************************\n",
      "Iteration  89 :Train Loss : 0.7470146  Train Accuracy:  0.95056\n",
      "            : Test Loss :0.7630392909049988 Test Accuracy : 0.9490299820899963 \n",
      "****************************************************************************************************\n",
      "Iteration  90 :Train Loss : 0.74457276  Train Accuracy:  0.95073\n",
      "            : Test Loss :0.7607027292251587 Test Accuracy : 0.9491699934005737 \n",
      "****************************************************************************************************\n",
      "Iteration  91 :Train Loss : 0.742168  Train Accuracy:  0.9508833\n",
      "            : Test Loss :0.7584020495414734 Test Accuracy : 0.9493200182914734 \n",
      "****************************************************************************************************\n",
      "Iteration  92 :Train Loss : 0.7397995  Train Accuracy:  0.95102334\n",
      "            : Test Loss :0.7561367154121399 Test Accuracy : 0.9494400024414062 \n",
      "****************************************************************************************************\n",
      "Iteration  93 :Train Loss : 0.73746634  Train Accuracy:  0.951185\n",
      "            : Test Loss :0.7539052963256836 Test Accuracy : 0.9495499730110168 \n",
      "****************************************************************************************************\n",
      "Iteration  94 :Train Loss : 0.73516744  Train Accuracy:  0.951335\n",
      "            : Test Loss :0.7517074942588806 Test Accuracy : 0.9496300220489502 \n",
      "****************************************************************************************************\n",
      "Iteration  95 :Train Loss : 0.73290193  Train Accuracy:  0.95146835\n",
      "            : Test Loss :0.7495421171188354 Test Accuracy : 0.9498699903488159 \n",
      "****************************************************************************************************\n",
      "Iteration  96 :Train Loss : 0.7306687  Train Accuracy:  0.951645\n",
      "            : Test Loss :0.7474083304405212 Test Accuracy : 0.9501000046730042 \n",
      "****************************************************************************************************\n",
      "Iteration  97 :Train Loss : 0.72846735  Train Accuracy:  0.95176333\n",
      "            : Test Loss :0.7453052997589111 Test Accuracy : 0.9502699971199036 \n",
      "****************************************************************************************************\n",
      "Iteration  98 :Train Loss : 0.7262968  Train Accuracy:  0.951905\n",
      "            : Test Loss :0.7432326078414917 Test Accuracy : 0.9503800272941589 \n",
      "****************************************************************************************************\n",
      "Iteration  99 :Train Loss : 0.7241564  Train Accuracy:  0.9520317\n",
      "            : Test Loss :0.7411888837814331 Test Accuracy : 0.9505699872970581 \n",
      "****************************************************************************************************\n",
      "Iteration  100 :Train Loss : 0.7220454  Train Accuracy:  0.95220166\n",
      "            : Test Loss :0.7391732931137085 Test Accuracy : 0.9506800174713135 \n",
      "****************************************************************************************************\n",
      "Iteration  101 :Train Loss : 0.71996325  Train Accuracy:  0.9523733\n",
      "            : Test Loss :0.7371852397918701 Test Accuracy : 0.9508000016212463 \n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  102 :Train Loss : 0.7179092  Train Accuracy:  0.95251\n",
      "            : Test Loss :0.7352235913276672 Test Accuracy : 0.9508900046348572 \n",
      "****************************************************************************************************\n",
      "Iteration  103 :Train Loss : 0.71588266  Train Accuracy:  0.9526233\n",
      "            : Test Loss :0.7332881093025208 Test Accuracy : 0.9510599970817566 \n",
      "****************************************************************************************************\n",
      "Iteration  104 :Train Loss : 0.7138828  Train Accuracy:  0.9527817\n",
      "            : Test Loss :0.7313782572746277 Test Accuracy : 0.9512199759483337 \n",
      "****************************************************************************************************\n",
      "Iteration  105 :Train Loss : 0.71190935  Train Accuracy:  0.95289665\n",
      "            : Test Loss :0.7294937372207642 Test Accuracy : 0.9513800144195557 \n",
      "****************************************************************************************************\n",
      "Iteration  106 :Train Loss : 0.7099616  Train Accuracy:  0.9530233\n",
      "            : Test Loss :0.7276337146759033 Test Accuracy : 0.951479971408844 \n",
      "****************************************************************************************************\n",
      "Iteration  107 :Train Loss : 0.70803905  Train Accuracy:  0.95315665\n",
      "            : Test Loss :0.7257980704307556 Test Accuracy : 0.9516400098800659 \n",
      "****************************************************************************************************\n",
      "Iteration  108 :Train Loss : 0.70614094  Train Accuracy:  0.95326835\n",
      "            : Test Loss :0.7239861488342285 Test Accuracy : 0.9517499804496765 \n",
      "****************************************************************************************************\n",
      "Iteration  109 :Train Loss : 0.70426685  Train Accuracy:  0.95339334\n",
      "            : Test Loss :0.7221976518630981 Test Accuracy : 0.9518600106239319 \n",
      "****************************************************************************************************\n",
      "Iteration  110 :Train Loss : 0.70241636  Train Accuracy:  0.95351833\n",
      "            : Test Loss :0.720431923866272 Test Accuracy : 0.9520099759101868 \n",
      "****************************************************************************************************\n",
      "Iteration  111 :Train Loss : 0.70058864  Train Accuracy:  0.95364165\n",
      "            : Test Loss :0.7186885476112366 Test Accuracy : 0.9520400166511536 \n",
      "****************************************************************************************************\n",
      "Iteration  112 :Train Loss : 0.69878393  Train Accuracy:  0.95374835\n",
      "            : Test Loss :0.7169666886329651 Test Accuracy : 0.952210009098053 \n",
      "****************************************************************************************************\n",
      "Iteration  113 :Train Loss : 0.69700104  Train Accuracy:  0.953865\n",
      "            : Test Loss :0.7152659296989441 Test Accuracy : 0.9523299932479858 \n",
      "****************************************************************************************************\n",
      "Iteration  114 :Train Loss : 0.69524  Train Accuracy:  0.9539833\n",
      "            : Test Loss :0.7135857939720154 Test Accuracy : 0.9524199962615967 \n",
      "****************************************************************************************************\n",
      "Iteration  115 :Train Loss : 0.6935  Train Accuracy:  0.95413166\n",
      "            : Test Loss :0.7119261622428894 Test Accuracy : 0.9525200128555298 \n",
      "****************************************************************************************************\n",
      "Iteration  116 :Train Loss : 0.69178087  Train Accuracy:  0.95426166\n",
      "            : Test Loss :0.7102864384651184 Test Accuracy : 0.9525700211524963 \n",
      "****************************************************************************************************\n",
      "Iteration  117 :Train Loss : 0.6900823  Train Accuracy:  0.95434165\n",
      "            : Test Loss :0.7086665630340576 Test Accuracy : 0.9526299834251404 \n",
      "****************************************************************************************************\n",
      "Iteration  118 :Train Loss : 0.68840367  Train Accuracy:  0.95444834\n",
      "            : Test Loss :0.7070659399032593 Test Accuracy : 0.9527199864387512 \n",
      "****************************************************************************************************\n",
      "Iteration  119 :Train Loss : 0.68674475  Train Accuracy:  0.95456165\n",
      "            : Test Loss :0.70548415184021 Test Accuracy : 0.9528200030326843 \n",
      "****************************************************************************************************\n",
      "Iteration  120 :Train Loss : 0.68510514  Train Accuracy:  0.95467\n",
      "            : Test Loss :0.7039212584495544 Test Accuracy : 0.9529299736022949 \n",
      "****************************************************************************************************\n",
      "Iteration  121 :Train Loss : 0.6834844  Train Accuracy:  0.95477\n",
      "            : Test Loss :0.7023765444755554 Test Accuracy : 0.9530199766159058 \n",
      "****************************************************************************************************\n",
      "Iteration  122 :Train Loss : 0.68188214  Train Accuracy:  0.9549017\n",
      "            : Test Loss :0.7008498311042786 Test Accuracy : 0.9530500173568726 \n",
      "****************************************************************************************************\n",
      "Iteration  123 :Train Loss : 0.68029815  Train Accuracy:  0.95501\n",
      "            : Test Loss :0.6993404030799866 Test Accuracy : 0.9531199932098389 \n",
      "****************************************************************************************************\n",
      "Iteration  124 :Train Loss : 0.67873216  Train Accuracy:  0.955125\n",
      "            : Test Loss :0.697848379611969 Test Accuracy : 0.9531800150871277 \n",
      "****************************************************************************************************\n",
      "Iteration  125 :Train Loss : 0.67718345  Train Accuracy:  0.95522\n",
      "            : Test Loss :0.696373462677002 Test Accuracy : 0.9532700181007385 \n",
      "****************************************************************************************************\n",
      "Iteration  126 :Train Loss : 0.6756524  Train Accuracy:  0.9553483\n",
      "            : Test Loss :0.6949150562286377 Test Accuracy : 0.9533799886703491 \n",
      "****************************************************************************************************\n",
      "Iteration  127 :Train Loss : 0.67413807  Train Accuracy:  0.9554833\n",
      "            : Test Loss :0.6934731006622314 Test Accuracy : 0.95346999168396 \n",
      "****************************************************************************************************\n",
      "Iteration  128 :Train Loss : 0.6726405  Train Accuracy:  0.9555867\n",
      "            : Test Loss :0.6920474767684937 Test Accuracy : 0.9535800218582153 \n",
      "****************************************************************************************************\n",
      "Iteration  129 :Train Loss : 0.6711591  Train Accuracy:  0.955715\n",
      "            : Test Loss :0.6906377673149109 Test Accuracy : 0.9537500143051147 \n",
      "****************************************************************************************************\n",
      "Iteration  130 :Train Loss : 0.669694  Train Accuracy:  0.95579\n",
      "            : Test Loss :0.6892436742782593 Test Accuracy : 0.9538000226020813 \n",
      "****************************************************************************************************\n",
      "Iteration  131 :Train Loss : 0.66824454  Train Accuracy:  0.95589\n",
      "            : Test Loss :0.6878649592399597 Test Accuracy : 0.9539200067520142 \n",
      "****************************************************************************************************\n",
      "Iteration  132 :Train Loss : 0.6668108  Train Accuracy:  0.956005\n",
      "            : Test Loss :0.6865013241767883 Test Accuracy : 0.954039990901947 \n",
      "****************************************************************************************************\n",
      "Iteration  133 :Train Loss : 0.66539216  Train Accuracy:  0.95611\n",
      "            : Test Loss :0.685152530670166 Test Accuracy : 0.9541000127792358 \n",
      "****************************************************************************************************\n",
      "Iteration  134 :Train Loss : 0.66398853  Train Accuracy:  0.95622164\n",
      "            : Test Loss :0.6838183403015137 Test Accuracy : 0.954259991645813 \n",
      "****************************************************************************************************\n",
      "Iteration  135 :Train Loss : 0.66259974  Train Accuracy:  0.956335\n",
      "            : Test Loss :0.6824982166290283 Test Accuracy : 0.9543300271034241 \n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  136 :Train Loss : 0.6612254  Train Accuracy:  0.95644164\n",
      "            : Test Loss :0.6811922788619995 Test Accuracy : 0.9543799757957458 \n",
      "****************************************************************************************************\n",
      "Iteration  137 :Train Loss : 0.65986544  Train Accuracy:  0.95653\n",
      "            : Test Loss :0.6798999905586243 Test Accuracy : 0.9545000195503235 \n",
      "****************************************************************************************************\n",
      "Iteration  138 :Train Loss : 0.6585194  Train Accuracy:  0.95662665\n",
      "            : Test Loss :0.6786211729049683 Test Accuracy : 0.9546300172805786 \n",
      "****************************************************************************************************\n",
      "Iteration  139 :Train Loss : 0.65718734  Train Accuracy:  0.9567083\n",
      "            : Test Loss :0.6773558259010315 Test Accuracy : 0.9546599984169006 \n",
      "****************************************************************************************************\n",
      "Iteration  140 :Train Loss : 0.65586877  Train Accuracy:  0.956785\n",
      "            : Test Loss :0.6761037707328796 Test Accuracy : 0.9547200202941895 \n",
      "****************************************************************************************************\n",
      "Iteration  141 :Train Loss : 0.65456367  Train Accuracy:  0.95688164\n",
      "            : Test Loss :0.6748644709587097 Test Accuracy : 0.9547899961471558 \n",
      "****************************************************************************************************\n",
      "Iteration  142 :Train Loss : 0.6532716  Train Accuracy:  0.9569783\n",
      "            : Test Loss :0.6736381649971008 Test Accuracy : 0.9548799991607666 \n",
      "****************************************************************************************************\n",
      "Iteration  143 :Train Loss : 0.6519927  Train Accuracy:  0.9570583\n",
      "            : Test Loss :0.6724244356155396 Test Accuracy : 0.9549599885940552 \n",
      "****************************************************************************************************\n",
      "Iteration  144 :Train Loss : 0.65072644  Train Accuracy:  0.9571533\n",
      "            : Test Loss :0.6712229251861572 Test Accuracy : 0.954990029335022 \n",
      "****************************************************************************************************\n",
      "Iteration  145 :Train Loss : 0.64947265  Train Accuracy:  0.9572383\n",
      "            : Test Loss :0.670033872127533 Test Accuracy : 0.9551100134849548 \n",
      "****************************************************************************************************\n",
      "Iteration  146 :Train Loss : 0.6482314  Train Accuracy:  0.95732\n",
      "            : Test Loss :0.6688567399978638 Test Accuracy : 0.9551900029182434 \n",
      "****************************************************************************************************\n",
      "Iteration  147 :Train Loss : 0.6470021  Train Accuracy:  0.957395\n",
      "            : Test Loss :0.6676915287971497 Test Accuracy : 0.9553099870681763 \n",
      "****************************************************************************************************\n",
      "Iteration  148 :Train Loss : 0.6457851  Train Accuracy:  0.95746833\n",
      "            : Test Loss :0.6665380597114563 Test Accuracy : 0.9553999900817871 \n",
      "****************************************************************************************************\n",
      "Iteration  149 :Train Loss : 0.6445797  Train Accuracy:  0.9575433\n",
      "            : Test Loss :0.6653960347175598 Test Accuracy : 0.9555400013923645 \n",
      "****************************************************************************************************\n",
      "Iteration  150 :Train Loss : 0.64338607  Train Accuracy:  0.9576217\n",
      "            : Test Loss :0.6642651557922363 Test Accuracy : 0.9556199908256531 \n",
      "****************************************************************************************************\n",
      "Iteration  151 :Train Loss : 0.64220375  Train Accuracy:  0.95772\n",
      "            : Test Loss :0.6631454825401306 Test Accuracy : 0.9556699991226196 \n",
      "****************************************************************************************************\n",
      "Iteration  152 :Train Loss : 0.6410329  Train Accuracy:  0.95778334\n",
      "            : Test Loss :0.6620365977287292 Test Accuracy : 0.9557399749755859 \n",
      "****************************************************************************************************\n",
      "Iteration  153 :Train Loss : 0.639873  Train Accuracy:  0.95785666\n",
      "            : Test Loss :0.6609386801719666 Test Accuracy : 0.9557899832725525 \n",
      "****************************************************************************************************\n",
      "Iteration  154 :Train Loss : 0.6387242  Train Accuracy:  0.9579433\n",
      "            : Test Loss :0.6598513722419739 Test Accuracy : 0.9559000134468079 \n",
      "****************************************************************************************************\n",
      "Iteration  155 :Train Loss : 0.6375861  Train Accuracy:  0.9580067\n",
      "            : Test Loss :0.658774733543396 Test Accuracy : 0.9560099840164185 \n",
      "****************************************************************************************************\n",
      "Iteration  156 :Train Loss : 0.6364589  Train Accuracy:  0.95808667\n",
      "            : Test Loss :0.6577082276344299 Test Accuracy : 0.9561100006103516 \n",
      "****************************************************************************************************\n",
      "Iteration  157 :Train Loss : 0.63534194  Train Accuracy:  0.9581533\n",
      "            : Test Loss :0.6566520929336548 Test Accuracy : 0.9562100172042847 \n",
      "****************************************************************************************************\n",
      "Iteration  158 :Train Loss : 0.63423526  Train Accuracy:  0.95825\n",
      "            : Test Loss :0.6556060314178467 Test Accuracy : 0.9562600255012512 \n",
      "****************************************************************************************************\n",
      "Iteration  159 :Train Loss : 0.633139  Train Accuracy:  0.958325\n",
      "            : Test Loss :0.6545700430870056 Test Accuracy : 0.9563000202178955 \n",
      "****************************************************************************************************\n",
      "Iteration  160 :Train Loss : 0.63205266  Train Accuracy:  0.9584117\n",
      "            : Test Loss :0.6535437107086182 Test Accuracy : 0.9563800096511841 \n",
      "****************************************************************************************************\n",
      "Iteration  161 :Train Loss : 0.6309763  Train Accuracy:  0.95848835\n",
      "            : Test Loss :0.6525270342826843 Test Accuracy : 0.9564700126647949 \n",
      "****************************************************************************************************\n",
      "Iteration  162 :Train Loss : 0.62990975  Train Accuracy:  0.95853335\n",
      "            : Test Loss :0.6515198349952698 Test Accuracy : 0.9564700126647949 \n",
      "****************************************************************************************************\n",
      "Iteration  163 :Train Loss : 0.6288527  Train Accuracy:  0.9585983\n",
      "            : Test Loss :0.650521993637085 Test Accuracy : 0.9565399885177612 \n",
      "****************************************************************************************************\n",
      "Iteration  164 :Train Loss : 0.62780523  Train Accuracy:  0.9586883\n",
      "            : Test Loss :0.6495333909988403 Test Accuracy : 0.9565899968147278 \n",
      "****************************************************************************************************\n",
      "Iteration  165 :Train Loss : 0.62676716  Train Accuracy:  0.958765\n",
      "            : Test Loss :0.6485539078712463 Test Accuracy : 0.9566400051116943 \n",
      "****************************************************************************************************\n",
      "Iteration  166 :Train Loss : 0.62573826  Train Accuracy:  0.9588417\n",
      "            : Test Loss :0.6475833654403687 Test Accuracy : 0.9567099809646606 \n",
      "****************************************************************************************************\n",
      "Iteration  167 :Train Loss : 0.62471855  Train Accuracy:  0.9589317\n",
      "            : Test Loss :0.6466217041015625 Test Accuracy : 0.9568099975585938 \n",
      "****************************************************************************************************\n",
      "Iteration  168 :Train Loss : 0.6237079  Train Accuracy:  0.95900166\n",
      "            : Test Loss :0.6456686854362488 Test Accuracy : 0.9568799734115601 \n",
      "****************************************************************************************************\n",
      "Iteration  169 :Train Loss : 0.62270594  Train Accuracy:  0.95906836\n",
      "            : Test Loss :0.6447246074676514 Test Accuracy : 0.9569500088691711 \n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  170 :Train Loss : 0.62171286  Train Accuracy:  0.959125\n",
      "            : Test Loss :0.6437888741493225 Test Accuracy : 0.957040011882782 \n",
      "****************************************************************************************************\n",
      "Iteration  171 :Train Loss : 0.6207284  Train Accuracy:  0.95917\n",
      "            : Test Loss :0.642861545085907 Test Accuracy : 0.9571300148963928 \n",
      "****************************************************************************************************\n",
      "Iteration  172 :Train Loss : 0.61975247  Train Accuracy:  0.9592417\n",
      "            : Test Loss :0.6419425010681152 Test Accuracy : 0.9572200179100037 \n",
      "****************************************************************************************************\n",
      "Iteration  173 :Train Loss : 0.61878496  Train Accuracy:  0.95928836\n",
      "            : Test Loss :0.6410316228866577 Test Accuracy : 0.9573000073432922 \n",
      "****************************************************************************************************\n",
      "Iteration  174 :Train Loss : 0.6178256  Train Accuracy:  0.9593383\n",
      "            : Test Loss :0.6401289701461792 Test Accuracy : 0.9573100209236145 \n",
      "****************************************************************************************************\n",
      "Iteration  175 :Train Loss : 0.6168747  Train Accuracy:  0.9594\n",
      "            : Test Loss :0.6392340660095215 Test Accuracy : 0.9573799967765808 \n",
      "****************************************************************************************************\n",
      "Iteration  176 :Train Loss : 0.6159317  Train Accuracy:  0.95947164\n",
      "            : Test Loss :0.6383471488952637 Test Accuracy : 0.9574400186538696 \n",
      "****************************************************************************************************\n",
      "Iteration  177 :Train Loss : 0.61499673  Train Accuracy:  0.9595367\n",
      "            : Test Loss :0.6374680399894714 Test Accuracy : 0.9575200080871582 \n",
      "****************************************************************************************************\n",
      "Iteration  178 :Train Loss : 0.6140697  Train Accuracy:  0.95958835\n",
      "            : Test Loss :0.6365965604782104 Test Accuracy : 0.9576399922370911 \n",
      "****************************************************************************************************\n",
      "Iteration  179 :Train Loss : 0.6131504  Train Accuracy:  0.9596717\n",
      "            : Test Loss :0.6357327699661255 Test Accuracy : 0.9577100276947021 \n",
      "****************************************************************************************************\n",
      "Iteration  180 :Train Loss : 0.6122388  Train Accuracy:  0.9597483\n",
      "            : Test Loss :0.6348763108253479 Test Accuracy : 0.9577599763870239 \n",
      "****************************************************************************************************\n",
      "Iteration  181 :Train Loss : 0.61133474  Train Accuracy:  0.9598117\n",
      "            : Test Loss :0.634027361869812 Test Accuracy : 0.9578400254249573 \n",
      "****************************************************************************************************\n",
      "Iteration  182 :Train Loss : 0.6104383  Train Accuracy:  0.95987666\n",
      "            : Test Loss :0.6331856846809387 Test Accuracy : 0.9578400254249573 \n",
      "****************************************************************************************************\n",
      "Iteration  183 :Train Loss : 0.60954905  Train Accuracy:  0.95992166\n",
      "            : Test Loss :0.6323511004447937 Test Accuracy : 0.957889974117279 \n",
      "****************************************************************************************************\n",
      "Iteration  184 :Train Loss : 0.6086672  Train Accuracy:  0.9599917\n",
      "            : Test Loss :0.6315237879753113 Test Accuracy : 0.9579499959945679 \n",
      "****************************************************************************************************\n",
      "Iteration  185 :Train Loss : 0.60779256  Train Accuracy:  0.9600217\n",
      "            : Test Loss :0.630703330039978 Test Accuracy : 0.9579799771308899 \n",
      "****************************************************************************************************\n",
      "Iteration  186 :Train Loss : 0.606925  Train Accuracy:  0.960065\n",
      "            : Test Loss :0.6298898458480835 Test Accuracy : 0.9580000042915344 \n",
      "****************************************************************************************************\n",
      "Iteration  187 :Train Loss : 0.6060645  Train Accuracy:  0.96013\n",
      "            : Test Loss :0.6290832757949829 Test Accuracy : 0.9580299854278564 \n",
      "****************************************************************************************************\n",
      "Iteration  188 :Train Loss : 0.605211  Train Accuracy:  0.96019334\n",
      "            : Test Loss :0.6282835006713867 Test Accuracy : 0.9581000208854675 \n",
      "****************************************************************************************************\n",
      "Iteration  189 :Train Loss : 0.6043644  Train Accuracy:  0.96026665\n",
      "            : Test Loss :0.6274902820587158 Test Accuracy : 0.9581500291824341 \n",
      "****************************************************************************************************\n",
      "Iteration  190 :Train Loss : 0.6035243  Train Accuracy:  0.9603267\n",
      "            : Test Loss :0.6267036199569702 Test Accuracy : 0.9581800103187561 \n",
      "****************************************************************************************************\n",
      "Iteration  191 :Train Loss : 0.60269123  Train Accuracy:  0.9603867\n",
      "            : Test Loss :0.6259236335754395 Test Accuracy : 0.9582399725914001 \n",
      "****************************************************************************************************\n",
      "Iteration  192 :Train Loss : 0.6018646  Train Accuracy:  0.960425\n",
      "            : Test Loss :0.6251500248908997 Test Accuracy : 0.958299994468689 \n",
      "****************************************************************************************************\n",
      "Iteration  193 :Train Loss : 0.60104454  Train Accuracy:  0.960495\n",
      "            : Test Loss :0.624382734298706 Test Accuracy : 0.9583699703216553 \n",
      "****************************************************************************************************\n",
      "Iteration  194 :Train Loss : 0.60023093  Train Accuracy:  0.9605617\n",
      "            : Test Loss :0.6236217617988586 Test Accuracy : 0.9584100246429443 \n",
      "****************************************************************************************************\n",
      "Iteration  195 :Train Loss : 0.59942377  Train Accuracy:  0.96061665\n",
      "            : Test Loss :0.6228671073913574 Test Accuracy : 0.9584400057792664 \n",
      "****************************************************************************************************\n",
      "Iteration  196 :Train Loss : 0.5986228  Train Accuracy:  0.96067667\n",
      "            : Test Loss :0.6221184730529785 Test Accuracy : 0.9584699869155884 \n",
      "****************************************************************************************************\n",
      "Iteration  197 :Train Loss : 0.59782815  Train Accuracy:  0.9607267\n",
      "            : Test Loss :0.6213757991790771 Test Accuracy : 0.9585199952125549 \n",
      "****************************************************************************************************\n",
      "Iteration  198 :Train Loss : 0.5970396  Train Accuracy:  0.96079165\n",
      "            : Test Loss :0.6206390857696533 Test Accuracy : 0.9585800170898438 \n",
      "****************************************************************************************************\n",
      "Iteration  199 :Train Loss : 0.59625715  Train Accuracy:  0.960845\n",
      "            : Test Loss :0.6199085116386414 Test Accuracy : 0.9586499929428101 \n",
      "****************************************************************************************************\n",
      "Iteration  200 :Train Loss : 0.5954807  Train Accuracy:  0.9609\n",
      "            : Test Loss :0.6191837191581726 Test Accuracy : 0.9587299823760986 \n",
      "****************************************************************************************************\n",
      "Iteration  201 :Train Loss : 0.59471023  Train Accuracy:  0.960955\n",
      "            : Test Loss :0.6184645295143127 Test Accuracy : 0.9588199853897095 \n",
      "****************************************************************************************************\n",
      "Iteration  202 :Train Loss : 0.5939457  Train Accuracy:  0.9610017\n",
      "            : Test Loss :0.6177513599395752 Test Accuracy : 0.958899974822998 \n",
      "****************************************************************************************************\n",
      "Iteration  203 :Train Loss : 0.5931868  Train Accuracy:  0.96105\n",
      "            : Test Loss :0.6170435547828674 Test Accuracy : 0.9589999914169312 \n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  204 :Train Loss : 0.59243375  Train Accuracy:  0.96109\n",
      "            : Test Loss :0.6163415312767029 Test Accuracy : 0.9590700268745422 \n",
      "****************************************************************************************************\n",
      "Iteration  205 :Train Loss : 0.5916863  Train Accuracy:  0.961145\n",
      "            : Test Loss :0.6156449913978577 Test Accuracy : 0.959119975566864 \n",
      "****************************************************************************************************\n",
      "Iteration  206 :Train Loss : 0.59094447  Train Accuracy:  0.96120167\n",
      "            : Test Loss :0.6149539351463318 Test Accuracy : 0.9591799974441528 \n",
      "****************************************************************************************************\n",
      "Iteration  207 :Train Loss : 0.59020835  Train Accuracy:  0.96126336\n",
      "            : Test Loss :0.6142680644989014 Test Accuracy : 0.9592499732971191 \n",
      "****************************************************************************************************\n",
      "Iteration  208 :Train Loss : 0.5894775  Train Accuracy:  0.9613233\n",
      "            : Test Loss :0.6135876774787903 Test Accuracy : 0.9592900276184082 \n",
      "****************************************************************************************************\n",
      "Iteration  209 :Train Loss : 0.5887522  Train Accuracy:  0.96137834\n",
      "            : Test Loss :0.6129125952720642 Test Accuracy : 0.9593700170516968 \n",
      "****************************************************************************************************\n",
      "Iteration  210 :Train Loss : 0.5880322  Train Accuracy:  0.96139836\n",
      "            : Test Loss :0.6122426986694336 Test Accuracy : 0.9594299793243408 \n",
      "****************************************************************************************************\n",
      "Iteration  211 :Train Loss : 0.58731747  Train Accuracy:  0.96144664\n",
      "            : Test Loss :0.6115778684616089 Test Accuracy : 0.9594500064849854 \n",
      "****************************************************************************************************\n",
      "Iteration  212 :Train Loss : 0.586608  Train Accuracy:  0.9614933\n",
      "            : Test Loss :0.6109181642532349 Test Accuracy : 0.9594799876213074 \n",
      "****************************************************************************************************\n",
      "Iteration  213 :Train Loss : 0.5859037  Train Accuracy:  0.96155167\n",
      "            : Test Loss :0.6102635264396667 Test Accuracy : 0.9595699906349182 \n",
      "****************************************************************************************************\n",
      "Iteration  214 :Train Loss : 0.5852046  Train Accuracy:  0.96162\n",
      "            : Test Loss :0.6096138954162598 Test Accuracy : 0.959630012512207 \n",
      "****************************************************************************************************\n",
      "Iteration  215 :Train Loss : 0.58451056  Train Accuracy:  0.96166664\n",
      "            : Test Loss :0.6089692115783691 Test Accuracy : 0.959630012512207 \n",
      "****************************************************************************************************\n",
      "Iteration  216 :Train Loss : 0.5838215  Train Accuracy:  0.961735\n",
      "            : Test Loss :0.6083292961120605 Test Accuracy : 0.9596499800682068 \n",
      "****************************************************************************************************\n",
      "Iteration  217 :Train Loss : 0.58313745  Train Accuracy:  0.96178335\n",
      "            : Test Loss :0.6076942086219788 Test Accuracy : 0.9597100019454956 \n",
      "****************************************************************************************************\n",
      "Iteration  218 :Train Loss : 0.5824582  Train Accuracy:  0.961815\n",
      "            : Test Loss :0.607063889503479 Test Accuracy : 0.9597100019454956 \n",
      "****************************************************************************************************\n",
      "Iteration  219 :Train Loss : 0.58178383  Train Accuracy:  0.9618483\n",
      "            : Test Loss :0.606438398361206 Test Accuracy : 0.9597300291061401 \n",
      "****************************************************************************************************\n",
      "Iteration  220 :Train Loss : 0.5811142  Train Accuracy:  0.9619\n",
      "            : Test Loss :0.6058174967765808 Test Accuracy : 0.9597799777984619 \n",
      "****************************************************************************************************\n",
      "Iteration  221 :Train Loss : 0.58044946  Train Accuracy:  0.961945\n",
      "            : Test Loss :0.6052011251449585 Test Accuracy : 0.959850013256073 \n",
      "****************************************************************************************************\n",
      "Iteration  222 :Train Loss : 0.5797893  Train Accuracy:  0.96198833\n",
      "            : Test Loss :0.6045892834663391 Test Accuracy : 0.959879994392395 \n",
      "****************************************************************************************************\n",
      "Iteration  223 :Train Loss : 0.57913387  Train Accuracy:  0.96203333\n",
      "            : Test Loss :0.6039820313453674 Test Accuracy : 0.9599000215530396 \n",
      "****************************************************************************************************\n",
      "Iteration  224 :Train Loss : 0.5784829  Train Accuracy:  0.9620817\n",
      "            : Test Loss :0.6033793687820435 Test Accuracy : 0.9599199891090393 \n",
      "****************************************************************************************************\n",
      "Iteration  225 :Train Loss : 0.5778367  Train Accuracy:  0.96213835\n",
      "            : Test Loss :0.6027808785438538 Test Accuracy : 0.9599999785423279 \n",
      "****************************************************************************************************\n",
      "Iteration  226 :Train Loss : 0.5771948  Train Accuracy:  0.96217334\n",
      "            : Test Loss :0.6021868586540222 Test Accuracy : 0.9600300192832947 \n",
      "****************************************************************************************************\n",
      "Iteration  227 :Train Loss : 0.5765573  Train Accuracy:  0.96221834\n",
      "            : Test Loss :0.6015970706939697 Test Accuracy : 0.9600499868392944 \n",
      "****************************************************************************************************\n",
      "Iteration  228 :Train Loss : 0.57592434  Train Accuracy:  0.9622667\n",
      "            : Test Loss :0.6010116934776306 Test Accuracy : 0.9601200222969055 \n",
      "****************************************************************************************************\n",
      "Iteration  229 :Train Loss : 0.5752957  Train Accuracy:  0.96231\n",
      "            : Test Loss :0.6004304885864258 Test Accuracy : 0.9601799845695496 \n",
      "****************************************************************************************************\n",
      "Iteration  230 :Train Loss : 0.5746713  Train Accuracy:  0.96236\n",
      "            : Test Loss :0.5998533368110657 Test Accuracy : 0.9602699875831604 \n",
      "****************************************************************************************************\n",
      "Iteration  231 :Train Loss : 0.5740514  Train Accuracy:  0.9624017\n",
      "            : Test Loss :0.599280595779419 Test Accuracy : 0.9603000283241272 \n",
      "****************************************************************************************************\n",
      "Iteration  232 :Train Loss : 0.5734354  Train Accuracy:  0.9624533\n",
      "            : Test Loss :0.5987116694450378 Test Accuracy : 0.9602900147438049 \n",
      "****************************************************************************************************\n",
      "Iteration  233 :Train Loss : 0.57282376  Train Accuracy:  0.96251\n",
      "            : Test Loss :0.598146915435791 Test Accuracy : 0.9603599905967712 \n",
      "****************************************************************************************************\n",
      "Iteration  234 :Train Loss : 0.5722162  Train Accuracy:  0.9625433\n",
      "            : Test Loss :0.5975862145423889 Test Accuracy : 0.9603999853134155 \n",
      "****************************************************************************************************\n",
      "Iteration  235 :Train Loss : 0.5716128  Train Accuracy:  0.962575\n",
      "            : Test Loss :0.5970295071601868 Test Accuracy : 0.9604600071907043 \n",
      "****************************************************************************************************\n",
      "Iteration  236 :Train Loss : 0.5710134  Train Accuracy:  0.96260166\n",
      "            : Test Loss :0.5964764356613159 Test Accuracy : 0.9604600071907043 \n",
      "****************************************************************************************************\n",
      "Iteration  237 :Train Loss : 0.57041794  Train Accuracy:  0.9626433\n",
      "            : Test Loss :0.5959275364875793 Test Accuracy : 0.9604700207710266 \n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  238 :Train Loss : 0.5698264  Train Accuracy:  0.96267664\n",
      "            : Test Loss :0.5953823924064636 Test Accuracy : 0.9605100154876709 \n",
      "****************************************************************************************************\n",
      "Iteration  239 :Train Loss : 0.569239  Train Accuracy:  0.96271664\n",
      "            : Test Loss :0.5948410034179688 Test Accuracy : 0.9605399966239929 \n",
      "****************************************************************************************************\n",
      "Iteration  240 :Train Loss : 0.5686553  Train Accuracy:  0.9627567\n",
      "            : Test Loss :0.5943033695220947 Test Accuracy : 0.9605799913406372 \n",
      "****************************************************************************************************\n",
      "Iteration  241 :Train Loss : 0.56807554  Train Accuracy:  0.962805\n",
      "            : Test Loss :0.5937695503234863 Test Accuracy : 0.9606500267982483 \n",
      "****************************************************************************************************\n",
      "Iteration  242 :Train Loss : 0.56749946  Train Accuracy:  0.962845\n",
      "            : Test Loss :0.5932393670082092 Test Accuracy : 0.9606500267982483 \n",
      "****************************************************************************************************\n",
      "Iteration  243 :Train Loss : 0.56692725  Train Accuracy:  0.96287\n",
      "            : Test Loss :0.5927128195762634 Test Accuracy : 0.9606900215148926 \n",
      "****************************************************************************************************\n",
      "Iteration  244 :Train Loss : 0.56635875  Train Accuracy:  0.96292\n",
      "            : Test Loss :0.5921899676322937 Test Accuracy : 0.9606800079345703 \n",
      "****************************************************************************************************\n",
      "Iteration  245 :Train Loss : 0.565794  Train Accuracy:  0.96296334\n",
      "            : Test Loss :0.5916705131530762 Test Accuracy : 0.960669994354248 \n",
      "****************************************************************************************************\n",
      "Iteration  246 :Train Loss : 0.5652328  Train Accuracy:  0.962995\n",
      "            : Test Loss :0.5911546349525452 Test Accuracy : 0.9607499837875366 \n",
      "****************************************************************************************************\n",
      "Iteration  247 :Train Loss : 0.5646753  Train Accuracy:  0.9630383\n",
      "            : Test Loss :0.5906423926353455 Test Accuracy : 0.9607999920845032 \n",
      "****************************************************************************************************\n",
      "Iteration  248 :Train Loss : 0.5641214  Train Accuracy:  0.963075\n",
      "            : Test Loss :0.5901333093643188 Test Accuracy : 0.9608399868011475 \n",
      "****************************************************************************************************\n",
      "Iteration  249 :Train Loss : 0.563571  Train Accuracy:  0.96310335\n",
      "            : Test Loss :0.5896280407905579 Test Accuracy : 0.9608700275421143 \n",
      "****************************************************************************************************\n",
      "Iteration  250 :Train Loss : 0.563024  Train Accuracy:  0.96312666\n",
      "            : Test Loss :0.5891260504722595 Test Accuracy : 0.9609500169754028 \n",
      "****************************************************************************************************\n",
      "Iteration  251 :Train Loss : 0.5624806  Train Accuracy:  0.96316165\n",
      "            : Test Loss :0.5886273384094238 Test Accuracy : 0.9609900116920471 \n",
      "****************************************************************************************************\n",
      "Iteration  252 :Train Loss : 0.56194067  Train Accuracy:  0.9631983\n",
      "            : Test Loss :0.5881320238113403 Test Accuracy : 0.9610599875450134 \n",
      "****************************************************************************************************\n",
      "Iteration  253 :Train Loss : 0.56140405  Train Accuracy:  0.96322334\n",
      "            : Test Loss :0.5876399278640747 Test Accuracy : 0.9610900282859802 \n",
      "****************************************************************************************************\n",
      "Iteration  254 :Train Loss : 0.5608708  Train Accuracy:  0.96325165\n",
      "            : Test Loss :0.587151050567627 Test Accuracy : 0.9611300230026245 \n",
      "****************************************************************************************************\n",
      "Iteration  255 :Train Loss : 0.56034106  Train Accuracy:  0.9632817\n",
      "            : Test Loss :0.5866653919219971 Test Accuracy : 0.961139976978302 \n",
      "****************************************************************************************************\n",
      "Iteration  256 :Train Loss : 0.55981445  Train Accuracy:  0.96331334\n",
      "            : Test Loss :0.5861830711364746 Test Accuracy : 0.9611799716949463 \n",
      "****************************************************************************************************\n",
      "Iteration  257 :Train Loss : 0.5592913  Train Accuracy:  0.96334165\n",
      "            : Test Loss :0.5857038497924805 Test Accuracy : 0.9612200260162354 \n",
      "****************************************************************************************************\n",
      "Iteration  258 :Train Loss : 0.5587713  Train Accuracy:  0.9633783\n",
      "            : Test Loss :0.5852277874946594 Test Accuracy : 0.9612799882888794 \n",
      "****************************************************************************************************\n",
      "Iteration  259 :Train Loss : 0.5582544  Train Accuracy:  0.963405\n",
      "            : Test Loss :0.5847547650337219 Test Accuracy : 0.9613000154495239 \n",
      "****************************************************************************************************\n",
      "Iteration  260 :Train Loss : 0.55774075  Train Accuracy:  0.963435\n",
      "            : Test Loss :0.5842848420143127 Test Accuracy : 0.9613500237464905 \n",
      "****************************************************************************************************\n",
      "Iteration  261 :Train Loss : 0.55723023  Train Accuracy:  0.9634783\n",
      "            : Test Loss :0.5838178992271423 Test Accuracy : 0.9613699913024902 \n",
      "****************************************************************************************************\n",
      "Iteration  262 :Train Loss : 0.55672294  Train Accuracy:  0.9635083\n",
      "            : Test Loss :0.5833540558815002 Test Accuracy : 0.9613800048828125 \n",
      "****************************************************************************************************\n",
      "Iteration  263 :Train Loss : 0.55621874  Train Accuracy:  0.96353835\n",
      "            : Test Loss :0.5828932523727417 Test Accuracy : 0.9614400267601013 \n",
      "****************************************************************************************************\n",
      "Iteration  264 :Train Loss : 0.5557175  Train Accuracy:  0.9635767\n",
      "            : Test Loss :0.5824352502822876 Test Accuracy : 0.9614800214767456 \n",
      "****************************************************************************************************\n",
      "Iteration  265 :Train Loss : 0.5552193  Train Accuracy:  0.96360165\n",
      "            : Test Loss :0.5819802284240723 Test Accuracy : 0.9614499807357788 \n",
      "****************************************************************************************************\n",
      "Iteration  266 :Train Loss : 0.5547242  Train Accuracy:  0.96363\n",
      "            : Test Loss :0.5815281271934509 Test Accuracy : 0.9614800214767456 \n",
      "****************************************************************************************************\n",
      "Iteration  267 :Train Loss : 0.55423206  Train Accuracy:  0.96365666\n",
      "            : Test Loss :0.5810790061950684 Test Accuracy : 0.9615200161933899 \n",
      "****************************************************************************************************\n",
      "Iteration  268 :Train Loss : 0.5537427  Train Accuracy:  0.963685\n",
      "            : Test Loss :0.5806324481964111 Test Accuracy : 0.9615899920463562 \n",
      "****************************************************************************************************\n",
      "Iteration  269 :Train Loss : 0.5532565  Train Accuracy:  0.9637117\n",
      "            : Test Loss :0.5801889300346375 Test Accuracy : 0.9616100192070007 \n",
      "****************************************************************************************************\n",
      "Iteration  270 :Train Loss : 0.55277306  Train Accuracy:  0.96375\n",
      "            : Test Loss :0.5797480344772339 Test Accuracy : 0.9616299867630005 \n",
      "****************************************************************************************************\n",
      "Iteration  271 :Train Loss : 0.5522925  Train Accuracy:  0.96379167\n",
      "            : Test Loss :0.5793099403381348 Test Accuracy : 0.961679995059967 \n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  272 :Train Loss : 0.5518148  Train Accuracy:  0.96381664\n",
      "            : Test Loss :0.5788747668266296 Test Accuracy : 0.9617199897766113 \n",
      "****************************************************************************************************\n",
      "Iteration  273 :Train Loss : 0.55133986  Train Accuracy:  0.9638517\n",
      "            : Test Loss :0.5784422755241394 Test Accuracy : 0.9617499709129333 \n",
      "****************************************************************************************************\n",
      "Iteration  274 :Train Loss : 0.5508678  Train Accuracy:  0.96388334\n",
      "            : Test Loss :0.5780124068260193 Test Accuracy : 0.9617900252342224 \n",
      "****************************************************************************************************\n",
      "Iteration  275 :Train Loss : 0.5503984  Train Accuracy:  0.9638967\n",
      "            : Test Loss :0.5775850415229797 Test Accuracy : 0.9617999792098999 \n",
      "****************************************************************************************************\n",
      "Iteration  276 :Train Loss : 0.5499319  Train Accuracy:  0.96392834\n",
      "            : Test Loss :0.5771604776382446 Test Accuracy : 0.9618200063705444 \n",
      "****************************************************************************************************\n",
      "Iteration  277 :Train Loss : 0.54946804  Train Accuracy:  0.96396\n",
      "            : Test Loss :0.5767384171485901 Test Accuracy : 0.9618600010871887 \n",
      "****************************************************************************************************\n",
      "Iteration  278 :Train Loss : 0.54900676  Train Accuracy:  0.96400666\n",
      "            : Test Loss :0.5763189196586609 Test Accuracy : 0.961870014667511 \n",
      "****************************************************************************************************\n",
      "Iteration  279 :Train Loss : 0.54854816  Train Accuracy:  0.964065\n",
      "            : Test Loss :0.5759021639823914 Test Accuracy : 0.9618899822235107 \n",
      "****************************************************************************************************\n",
      "Iteration  280 :Train Loss : 0.5480923  Train Accuracy:  0.9641067\n",
      "            : Test Loss :0.5754877328872681 Test Accuracy : 0.961899995803833 \n",
      "****************************************************************************************************\n",
      "Iteration  281 :Train Loss : 0.5476391  Train Accuracy:  0.96414\n",
      "            : Test Loss :0.5750758647918701 Test Accuracy : 0.9619200229644775 \n",
      "****************************************************************************************************\n",
      "Iteration  282 :Train Loss : 0.5471883  Train Accuracy:  0.96416\n",
      "            : Test Loss :0.5746666193008423 Test Accuracy : 0.9619200229644775 \n",
      "****************************************************************************************************\n",
      "Iteration  283 :Train Loss : 0.5467402  Train Accuracy:  0.9642\n",
      "            : Test Loss :0.5742597579956055 Test Accuracy : 0.9619500041007996 \n",
      "****************************************************************************************************\n",
      "Iteration  284 :Train Loss : 0.54629457  Train Accuracy:  0.96423167\n",
      "            : Test Loss :0.5738552212715149 Test Accuracy : 0.9619899988174438 \n",
      "****************************************************************************************************\n",
      "Iteration  285 :Train Loss : 0.5458515  Train Accuracy:  0.9642633\n",
      "            : Test Loss :0.5734532475471497 Test Accuracy : 0.9620000123977661 \n",
      "****************************************************************************************************\n",
      "Iteration  286 :Train Loss : 0.54541093  Train Accuracy:  0.9642917\n",
      "            : Test Loss :0.5730537176132202 Test Accuracy : 0.9620400071144104 \n",
      "****************************************************************************************************\n",
      "Iteration  287 :Train Loss : 0.5449729  Train Accuracy:  0.96431\n",
      "            : Test Loss :0.5726564526557922 Test Accuracy : 0.9620599746704102 \n",
      "****************************************************************************************************\n",
      "Iteration  288 :Train Loss : 0.54453725  Train Accuracy:  0.964335\n",
      "            : Test Loss :0.5722615122795105 Test Accuracy : 0.9620599746704102 \n",
      "****************************************************************************************************\n",
      "Iteration  289 :Train Loss : 0.54410386  Train Accuracy:  0.96436\n",
      "            : Test Loss :0.5718690156936646 Test Accuracy : 0.9621099829673767 \n",
      "****************************************************************************************************\n",
      "Iteration  290 :Train Loss : 0.54367316  Train Accuracy:  0.9643817\n",
      "            : Test Loss :0.5714787840843201 Test Accuracy : 0.9621099829673767 \n",
      "****************************************************************************************************\n",
      "Iteration  291 :Train Loss : 0.54324484  Train Accuracy:  0.96441\n",
      "            : Test Loss :0.571090817451477 Test Accuracy : 0.9621700048446655 \n",
      "****************************************************************************************************\n",
      "Iteration  292 :Train Loss : 0.54281867  Train Accuracy:  0.9644433\n",
      "            : Test Loss :0.570704996585846 Test Accuracy : 0.9622300267219543 \n",
      "****************************************************************************************************\n",
      "Iteration  293 :Train Loss : 0.54239506  Train Accuracy:  0.96445334\n",
      "            : Test Loss :0.5703216791152954 Test Accuracy : 0.9622499942779541 \n",
      "****************************************************************************************************\n",
      "Iteration  294 :Train Loss : 0.5419737  Train Accuracy:  0.9645017\n",
      "            : Test Loss :0.569940447807312 Test Accuracy : 0.9623100161552429 \n",
      "****************************************************************************************************\n",
      "Iteration  295 :Train Loss : 0.5415545  Train Accuracy:  0.9645233\n",
      "            : Test Loss :0.5695614218711853 Test Accuracy : 0.9623299837112427 \n",
      "****************************************************************************************************\n",
      "Iteration  296 :Train Loss : 0.54113775  Train Accuracy:  0.96456\n",
      "            : Test Loss :0.5691846609115601 Test Accuracy : 0.9623500108718872 \n",
      "****************************************************************************************************\n",
      "Iteration  297 :Train Loss : 0.54072326  Train Accuracy:  0.964595\n",
      "            : Test Loss :0.5688101053237915 Test Accuracy : 0.9623299837112427 \n",
      "****************************************************************************************************\n",
      "Iteration  298 :Train Loss : 0.5403109  Train Accuracy:  0.96462333\n",
      "            : Test Loss :0.5684375762939453 Test Accuracy : 0.9624000191688538 \n",
      "****************************************************************************************************\n",
      "Iteration  299 :Train Loss : 0.539901  Train Accuracy:  0.9646583\n",
      "            : Test Loss :0.5680673122406006 Test Accuracy : 0.9624099731445312 \n",
      "****************************************************************************************************\n",
      "Iteration  300 :Train Loss : 0.53949314  Train Accuracy:  0.9647\n",
      "            : Test Loss :0.567699134349823 Test Accuracy : 0.9624099731445312 \n",
      "****************************************************************************************************\n",
      "Iteration  301 :Train Loss : 0.5390875  Train Accuracy:  0.964735\n",
      "            : Test Loss :0.5673329830169678 Test Accuracy : 0.9624099731445312 \n",
      "****************************************************************************************************\n",
      "Iteration  302 :Train Loss : 0.538684  Train Accuracy:  0.96476334\n",
      "            : Test Loss :0.5669689178466797 Test Accuracy : 0.9624500274658203 \n",
      "****************************************************************************************************\n",
      "Iteration  303 :Train Loss : 0.5382827  Train Accuracy:  0.964775\n",
      "            : Test Loss :0.5666069388389587 Test Accuracy : 0.9624800086021423 \n",
      "****************************************************************************************************\n",
      "Iteration  304 :Train Loss : 0.53788346  Train Accuracy:  0.96480334\n",
      "            : Test Loss :0.5662470459938049 Test Accuracy : 0.9624800086021423 \n",
      "****************************************************************************************************\n",
      "Iteration  305 :Train Loss : 0.5374864  Train Accuracy:  0.96481836\n",
      "            : Test Loss :0.5658890604972839 Test Accuracy : 0.9624999761581421 \n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  306 :Train Loss : 0.53709143  Train Accuracy:  0.9648467\n",
      "            : Test Loss :0.5655331015586853 Test Accuracy : 0.9625599980354309 \n",
      "****************************************************************************************************\n",
      "Iteration  307 :Train Loss : 0.53669846  Train Accuracy:  0.96488166\n",
      "            : Test Loss :0.5651792287826538 Test Accuracy : 0.9625700116157532 \n",
      "****************************************************************************************************\n",
      "Iteration  308 :Train Loss : 0.5363077  Train Accuracy:  0.964915\n",
      "            : Test Loss :0.5648272037506104 Test Accuracy : 0.9625899791717529 \n",
      "****************************************************************************************************\n",
      "Iteration  309 :Train Loss : 0.5359189  Train Accuracy:  0.9649517\n",
      "            : Test Loss :0.5644772052764893 Test Accuracy : 0.9625999927520752 \n",
      "****************************************************************************************************\n",
      "Iteration  310 :Train Loss : 0.5355321  Train Accuracy:  0.964965\n",
      "            : Test Loss :0.564129114151001 Test Accuracy : 0.9625700116157532 \n",
      "****************************************************************************************************\n",
      "Iteration  311 :Train Loss : 0.5351473  Train Accuracy:  0.9649967\n",
      "            : Test Loss :0.5637829899787903 Test Accuracy : 0.9625999927520752 \n",
      "****************************************************************************************************\n",
      "Iteration  312 :Train Loss : 0.53476447  Train Accuracy:  0.96502167\n",
      "            : Test Loss :0.5634386539459229 Test Accuracy : 0.9626299738883972 \n",
      "****************************************************************************************************\n",
      "Iteration  313 :Train Loss : 0.5343838  Train Accuracy:  0.96504\n",
      "            : Test Loss :0.5630965232849121 Test Accuracy : 0.9626799821853638 \n",
      "****************************************************************************************************\n",
      "Iteration  314 :Train Loss : 0.5340049  Train Accuracy:  0.965065\n",
      "            : Test Loss :0.5627558827400208 Test Accuracy : 0.9627100229263306 \n",
      "****************************************************************************************************\n",
      "Iteration  315 :Train Loss : 0.533628  Train Accuracy:  0.96509665\n",
      "            : Test Loss :0.5624173283576965 Test Accuracy : 0.9627400040626526 \n",
      "****************************************************************************************************\n",
      "Iteration  316 :Train Loss : 0.533253  Train Accuracy:  0.965125\n",
      "            : Test Loss :0.5620805025100708 Test Accuracy : 0.9627799987792969 \n",
      "****************************************************************************************************\n",
      "Iteration  317 :Train Loss : 0.53287995  Train Accuracy:  0.9651383\n",
      "            : Test Loss :0.5617454648017883 Test Accuracy : 0.9627900123596191 \n",
      "****************************************************************************************************\n",
      "Iteration  318 :Train Loss : 0.53250885  Train Accuracy:  0.9651717\n",
      "            : Test Loss :0.5614123344421387 Test Accuracy : 0.9628000259399414 \n",
      "****************************************************************************************************\n",
      "Iteration  319 :Train Loss : 0.5321395  Train Accuracy:  0.96520835\n",
      "            : Test Loss :0.5610811710357666 Test Accuracy : 0.9628099799156189 \n",
      "****************************************************************************************************\n",
      "Iteration  320 :Train Loss : 0.53177214  Train Accuracy:  0.96524835\n",
      "            : Test Loss :0.5607513785362244 Test Accuracy : 0.9628300070762634 \n",
      "****************************************************************************************************\n",
      "Iteration  321 :Train Loss : 0.5314065  Train Accuracy:  0.96526164\n",
      "            : Test Loss :0.5604234933853149 Test Accuracy : 0.96288001537323 \n",
      "****************************************************************************************************\n",
      "Iteration  322 :Train Loss : 0.5310428  Train Accuracy:  0.96528\n",
      "            : Test Loss :0.5600975751876831 Test Accuracy : 0.9629200100898743 \n",
      "****************************************************************************************************\n",
      "Iteration  323 :Train Loss : 0.53068084  Train Accuracy:  0.96532\n",
      "            : Test Loss :0.5597730278968811 Test Accuracy : 0.962939977645874 \n",
      "****************************************************************************************************\n",
      "Iteration  324 :Train Loss : 0.53032076  Train Accuracy:  0.96534336\n",
      "            : Test Loss :0.5594505667686462 Test Accuracy : 0.9629799723625183 \n",
      "****************************************************************************************************\n",
      "Iteration  325 :Train Loss : 0.5299624  Train Accuracy:  0.9653583\n",
      "            : Test Loss :0.5591295957565308 Test Accuracy : 0.9630299806594849 \n",
      "****************************************************************************************************\n",
      "Iteration  326 :Train Loss : 0.52960587  Train Accuracy:  0.96536666\n",
      "            : Test Loss :0.5588103532791138 Test Accuracy : 0.9630500078201294 \n",
      "****************************************************************************************************\n",
      "Iteration  327 :Train Loss : 0.52925116  Train Accuracy:  0.9653867\n",
      "            : Test Loss :0.55849289894104 Test Accuracy : 0.9630600214004517 \n",
      "****************************************************************************************************\n",
      "Iteration  328 :Train Loss : 0.528898  Train Accuracy:  0.96541667\n",
      "            : Test Loss :0.5581769347190857 Test Accuracy : 0.9630399942398071 \n",
      "****************************************************************************************************\n",
      "Iteration  329 :Train Loss : 0.52854675  Train Accuracy:  0.96545\n",
      "            : Test Loss :0.5578626990318298 Test Accuracy : 0.9630299806594849 \n",
      "****************************************************************************************************\n",
      "Iteration  330 :Train Loss : 0.5281971  Train Accuracy:  0.9654617\n",
      "            : Test Loss :0.5575501918792725 Test Accuracy : 0.9630799889564514 \n",
      "****************************************************************************************************\n",
      "Iteration  331 :Train Loss : 0.52784926  Train Accuracy:  0.96547836\n",
      "            : Test Loss :0.5572392344474792 Test Accuracy : 0.9630699753761292 \n",
      "****************************************************************************************************\n",
      "Iteration  332 :Train Loss : 0.527503  Train Accuracy:  0.96550834\n",
      "            : Test Loss :0.556929886341095 Test Accuracy : 0.9630500078201294 \n",
      "****************************************************************************************************\n",
      "Iteration  333 :Train Loss : 0.52715856  Train Accuracy:  0.9655283\n",
      "            : Test Loss :0.5566220879554749 Test Accuracy : 0.963100016117096 \n",
      "****************************************************************************************************\n",
      "Iteration  334 :Train Loss : 0.5268158  Train Accuracy:  0.96555835\n",
      "            : Test Loss :0.5563158392906189 Test Accuracy : 0.9631199836730957 \n",
      "****************************************************************************************************\n",
      "Iteration  335 :Train Loss : 0.52647454  Train Accuracy:  0.9655783\n",
      "            : Test Loss :0.5560113191604614 Test Accuracy : 0.963100016117096 \n",
      "****************************************************************************************************\n",
      "Iteration  336 :Train Loss : 0.52613497  Train Accuracy:  0.9656017\n",
      "            : Test Loss :0.5557082891464233 Test Accuracy : 0.963129997253418 \n",
      "****************************************************************************************************\n",
      "Iteration  337 :Train Loss : 0.52579695  Train Accuracy:  0.9656117\n",
      "            : Test Loss :0.5554068088531494 Test Accuracy : 0.9631400108337402 \n",
      "****************************************************************************************************\n",
      "Iteration  338 :Train Loss : 0.52546066  Train Accuracy:  0.96562666\n",
      "            : Test Loss :0.5551069378852844 Test Accuracy : 0.9631500244140625 \n",
      "****************************************************************************************************\n",
      "Iteration  339 :Train Loss : 0.5251259  Train Accuracy:  0.96565\n",
      "            : Test Loss :0.554808497428894 Test Accuracy : 0.9631699919700623 \n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  340 :Train Loss : 0.5247928  Train Accuracy:  0.965685\n",
      "            : Test Loss :0.554511547088623 Test Accuracy : 0.9631900191307068 \n",
      "****************************************************************************************************\n",
      "Iteration  341 :Train Loss : 0.5244613  Train Accuracy:  0.96571666\n",
      "            : Test Loss :0.5542160868644714 Test Accuracy : 0.9632400274276733 \n",
      "****************************************************************************************************\n",
      "Iteration  342 :Train Loss : 0.5241313  Train Accuracy:  0.96574\n",
      "            : Test Loss :0.553922176361084 Test Accuracy : 0.9632700085639954 \n",
      "****************************************************************************************************\n",
      "Iteration  343 :Train Loss : 0.5238028  Train Accuracy:  0.96576166\n",
      "            : Test Loss :0.5536296963691711 Test Accuracy : 0.9632599949836731 \n",
      "****************************************************************************************************\n",
      "Iteration  344 :Train Loss : 0.523476  Train Accuracy:  0.96579\n",
      "            : Test Loss :0.5533386468887329 Test Accuracy : 0.9632700085639954 \n",
      "****************************************************************************************************\n",
      "Iteration  345 :Train Loss : 0.52315056  Train Accuracy:  0.9658167\n",
      "            : Test Loss :0.5530492067337036 Test Accuracy : 0.9632999897003174 \n",
      "****************************************************************************************************\n",
      "Iteration  346 :Train Loss : 0.5228267  Train Accuracy:  0.9658267\n",
      "            : Test Loss :0.5527610778808594 Test Accuracy : 0.9633399844169617 \n",
      "****************************************************************************************************\n",
      "Iteration  347 :Train Loss : 0.52250427  Train Accuracy:  0.9658483\n",
      "            : Test Loss :0.5524744391441345 Test Accuracy : 0.9633600115776062 \n",
      "****************************************************************************************************\n",
      "Iteration  348 :Train Loss : 0.5221835  Train Accuracy:  0.96586835\n",
      "            : Test Loss :0.5521892309188843 Test Accuracy : 0.9634000062942505 \n",
      "****************************************************************************************************\n",
      "Iteration  349 :Train Loss : 0.5218642  Train Accuracy:  0.9658783\n",
      "            : Test Loss :0.5519053936004639 Test Accuracy : 0.9634299874305725 \n",
      "****************************************************************************************************\n",
      "Iteration  350 :Train Loss : 0.52154624  Train Accuracy:  0.9659\n",
      "            : Test Loss :0.5516228675842285 Test Accuracy : 0.9634699821472168 \n",
      "****************************************************************************************************\n",
      "Iteration  351 :Train Loss : 0.5212298  Train Accuracy:  0.965905\n",
      "            : Test Loss :0.551341712474823 Test Accuracy : 0.9635099768638611 \n",
      "****************************************************************************************************\n",
      "Iteration  352 :Train Loss : 0.5209148  Train Accuracy:  0.9659167\n",
      "            : Test Loss :0.5510619878768921 Test Accuracy : 0.9634799957275391 \n",
      "****************************************************************************************************\n",
      "Iteration  353 :Train Loss : 0.52060115  Train Accuracy:  0.9659383\n",
      "            : Test Loss :0.5507838129997253 Test Accuracy : 0.9635000228881836 \n",
      "****************************************************************************************************\n",
      "Iteration  354 :Train Loss : 0.520289  Train Accuracy:  0.965955\n",
      "            : Test Loss :0.5505068302154541 Test Accuracy : 0.9635099768638611 \n",
      "****************************************************************************************************\n",
      "Iteration  355 :Train Loss : 0.51997834  Train Accuracy:  0.96597\n",
      "            : Test Loss :0.5502312183380127 Test Accuracy : 0.9635099768638611 \n",
      "****************************************************************************************************\n",
      "Iteration  356 :Train Loss : 0.51966894  Train Accuracy:  0.96598333\n",
      "            : Test Loss :0.5499569177627563 Test Accuracy : 0.9635300040245056 \n",
      "****************************************************************************************************\n",
      "Iteration  357 :Train Loss : 0.5193611  Train Accuracy:  0.9660017\n",
      "            : Test Loss :0.5496838688850403 Test Accuracy : 0.9635400176048279 \n",
      "****************************************************************************************************\n",
      "Iteration  358 :Train Loss : 0.5190545  Train Accuracy:  0.96602666\n",
      "            : Test Loss :0.549412190914154 Test Accuracy : 0.9635699987411499 \n",
      "****************************************************************************************************\n",
      "Iteration  359 :Train Loss : 0.51874936  Train Accuracy:  0.9660533\n",
      "            : Test Loss :0.5491418838500977 Test Accuracy : 0.9635800123214722 \n",
      "****************************************************************************************************\n",
      "Iteration  360 :Train Loss : 0.5184456  Train Accuracy:  0.9660633\n",
      "            : Test Loss :0.5488729476928711 Test Accuracy : 0.9635800123214722 \n",
      "****************************************************************************************************\n",
      "Iteration  361 :Train Loss : 0.5181432  Train Accuracy:  0.9660633\n",
      "            : Test Loss :0.54860520362854 Test Accuracy : 0.9636099934577942 \n",
      "****************************************************************************************************\n",
      "Iteration  362 :Train Loss : 0.51784205  Train Accuracy:  0.966085\n",
      "            : Test Loss :0.5483385920524597 Test Accuracy : 0.9636099934577942 \n",
      "****************************************************************************************************\n",
      "Iteration  363 :Train Loss : 0.5175422  Train Accuracy:  0.9661\n",
      "            : Test Loss :0.548073410987854 Test Accuracy : 0.9636399745941162 \n",
      "****************************************************************************************************\n",
      "Iteration  364 :Train Loss : 0.5172438  Train Accuracy:  0.9661217\n",
      "            : Test Loss :0.547809362411499 Test Accuracy : 0.9636600017547607 \n",
      "****************************************************************************************************\n",
      "Iteration  365 :Train Loss : 0.5169466  Train Accuracy:  0.96614164\n",
      "            : Test Loss :0.5475466847419739 Test Accuracy : 0.9636600017547607 \n",
      "****************************************************************************************************\n",
      "Iteration  366 :Train Loss : 0.5166508  Train Accuracy:  0.9661483\n",
      "            : Test Loss :0.5472853183746338 Test Accuracy : 0.963699996471405 \n",
      "****************************************************************************************************\n",
      "Iteration  367 :Train Loss : 0.5163563  Train Accuracy:  0.96618\n",
      "            : Test Loss :0.5470249056816101 Test Accuracy : 0.9637399911880493 \n",
      "****************************************************************************************************\n",
      "Iteration  368 :Train Loss : 0.51606303  Train Accuracy:  0.96620333\n",
      "            : Test Loss :0.5467658042907715 Test Accuracy : 0.9637899994850159 \n",
      "****************************************************************************************************\n",
      "Iteration  369 :Train Loss : 0.51577103  Train Accuracy:  0.9662217\n",
      "            : Test Loss :0.5465078949928284 Test Accuracy : 0.9638199806213379 \n",
      "****************************************************************************************************\n",
      "Iteration  370 :Train Loss : 0.51548034  Train Accuracy:  0.9662433\n",
      "            : Test Loss :0.5462513566017151 Test Accuracy : 0.9638500213623047 \n",
      "****************************************************************************************************\n",
      "Iteration  371 :Train Loss : 0.51519096  Train Accuracy:  0.96626\n",
      "            : Test Loss :0.5459960699081421 Test Accuracy : 0.9638599753379822 \n",
      "****************************************************************************************************\n",
      "Iteration  372 :Train Loss : 0.5149027  Train Accuracy:  0.96627164\n",
      "            : Test Loss :0.5457416772842407 Test Accuracy : 0.963890016078949 \n",
      "****************************************************************************************************\n",
      "Iteration  373 :Train Loss : 0.5146158  Train Accuracy:  0.96628666\n",
      "            : Test Loss :0.5454885959625244 Test Accuracy : 0.9639000296592712 \n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  374 :Train Loss : 0.51433  Train Accuracy:  0.96632\n",
      "            : Test Loss :0.5452367067337036 Test Accuracy : 0.9639099836349487 \n",
      "****************************************************************************************************\n",
      "Iteration  375 :Train Loss : 0.5140456  Train Accuracy:  0.96635\n",
      "            : Test Loss :0.5449859499931335 Test Accuracy : 0.963949978351593 \n",
      "****************************************************************************************************\n",
      "Iteration  376 :Train Loss : 0.51376224  Train Accuracy:  0.96637166\n",
      "            : Test Loss :0.5447363257408142 Test Accuracy : 0.9639599919319153 \n",
      "****************************************************************************************************\n",
      "Iteration  377 :Train Loss : 0.5134801  Train Accuracy:  0.96638\n",
      "            : Test Loss :0.5444880127906799 Test Accuracy : 0.9639800190925598 \n",
      "****************************************************************************************************\n",
      "Iteration  378 :Train Loss : 0.51319927  Train Accuracy:  0.9664017\n",
      "            : Test Loss :0.5442406535148621 Test Accuracy : 0.9640100002288818 \n",
      "****************************************************************************************************\n",
      "Iteration  379 :Train Loss : 0.5129196  Train Accuracy:  0.96642\n",
      "            : Test Loss :0.5439943075180054 Test Accuracy : 0.9639999866485596 \n",
      "****************************************************************************************************\n",
      "Iteration  380 :Train Loss : 0.5126411  Train Accuracy:  0.966435\n",
      "            : Test Loss :0.5437490940093994 Test Accuracy : 0.9640499949455261 \n",
      "****************************************************************************************************\n",
      "Iteration  381 :Train Loss : 0.51236373  Train Accuracy:  0.9664583\n",
      "            : Test Loss :0.5435052514076233 Test Accuracy : 0.9640399813652039 \n",
      "****************************************************************************************************\n",
      "Iteration  382 :Train Loss : 0.5120876  Train Accuracy:  0.96647\n",
      "            : Test Loss :0.5432624220848083 Test Accuracy : 0.9640899896621704 \n",
      "****************************************************************************************************\n",
      "Iteration  383 :Train Loss : 0.5118125  Train Accuracy:  0.966495\n",
      "            : Test Loss :0.543020486831665 Test Accuracy : 0.9640700221061707 \n",
      "****************************************************************************************************\n",
      "Iteration  384 :Train Loss : 0.5115386  Train Accuracy:  0.966505\n",
      "            : Test Loss :0.5427798628807068 Test Accuracy : 0.9641500115394592 \n",
      "****************************************************************************************************\n",
      "Iteration  385 :Train Loss : 0.51126593  Train Accuracy:  0.9665267\n",
      "            : Test Loss :0.5425402522087097 Test Accuracy : 0.9642300009727478 \n",
      "****************************************************************************************************\n",
      "Iteration  386 :Train Loss : 0.5109943  Train Accuracy:  0.966535\n",
      "            : Test Loss :0.5423017144203186 Test Accuracy : 0.9642599821090698 \n",
      "****************************************************************************************************\n",
      "Iteration  387 :Train Loss : 0.5107239  Train Accuracy:  0.96655\n",
      "            : Test Loss :0.5420641899108887 Test Accuracy : 0.9642599821090698 \n",
      "****************************************************************************************************\n",
      "Iteration  388 :Train Loss : 0.5104545  Train Accuracy:  0.966575\n",
      "            : Test Loss :0.5418277382850647 Test Accuracy : 0.9642400145530701 \n",
      "****************************************************************************************************\n",
      "Iteration  389 :Train Loss : 0.5101862  Train Accuracy:  0.966605\n",
      "            : Test Loss :0.5415923595428467 Test Accuracy : 0.9642699956893921 \n",
      "****************************************************************************************************\n",
      "Iteration  390 :Train Loss : 0.5099191  Train Accuracy:  0.9666333\n",
      "            : Test Loss :0.5413580536842346 Test Accuracy : 0.9643099904060364 \n",
      "****************************************************************************************************\n",
      "Iteration  391 :Train Loss : 0.50965303  Train Accuracy:  0.966645\n",
      "            : Test Loss :0.5411246418952942 Test Accuracy : 0.9643200039863586 \n",
      "****************************************************************************************************\n",
      "Iteration  392 :Train Loss : 0.509388  Train Accuracy:  0.9666783\n",
      "            : Test Loss :0.5408924221992493 Test Accuracy : 0.9643300175666809 \n",
      "****************************************************************************************************\n",
      "Iteration  393 :Train Loss : 0.50912416  Train Accuracy:  0.966695\n",
      "            : Test Loss :0.5406611561775208 Test Accuracy : 0.9643700122833252 \n",
      "****************************************************************************************************\n",
      "Iteration  394 :Train Loss : 0.50886136  Train Accuracy:  0.9667067\n",
      "            : Test Loss :0.5404308438301086 Test Accuracy : 0.964389979839325 \n",
      "****************************************************************************************************\n",
      "Iteration  395 :Train Loss : 0.50859964  Train Accuracy:  0.966725\n",
      "            : Test Loss :0.5402015447616577 Test Accuracy : 0.9644299745559692 \n",
      "****************************************************************************************************\n",
      "Iteration  396 :Train Loss : 0.50833887  Train Accuracy:  0.96673834\n",
      "            : Test Loss :0.539973258972168 Test Accuracy : 0.964460015296936 \n",
      "****************************************************************************************************\n",
      "Iteration  397 :Train Loss : 0.5080792  Train Accuracy:  0.9667583\n",
      "            : Test Loss :0.539746105670929 Test Accuracy : 0.9644700288772583 \n",
      "****************************************************************************************************\n",
      "Iteration  398 :Train Loss : 0.50782055  Train Accuracy:  0.96677834\n",
      "            : Test Loss :0.539519727230072 Test Accuracy : 0.964460015296936 \n",
      "****************************************************************************************************\n",
      "Iteration  399 :Train Loss : 0.507563  Train Accuracy:  0.96680164\n",
      "            : Test Loss :0.539294421672821 Test Accuracy : 0.9644799828529358 \n",
      "****************************************************************************************************\n",
      "Iteration  400 :Train Loss : 0.50730646  Train Accuracy:  0.966825\n",
      "            : Test Loss :0.5390701293945312 Test Accuracy : 0.9645100235939026 \n",
      "****************************************************************************************************\n",
      "Iteration  401 :Train Loss : 0.50705093  Train Accuracy:  0.96682\n",
      "            : Test Loss :0.5388468503952026 Test Accuracy : 0.9645199775695801 \n",
      "****************************************************************************************************\n",
      "Iteration  402 :Train Loss : 0.5067964  Train Accuracy:  0.96683335\n",
      "            : Test Loss :0.5386244654655457 Test Accuracy : 0.9645100235939026 \n",
      "****************************************************************************************************\n",
      "Iteration  403 :Train Loss : 0.5065429  Train Accuracy:  0.9668367\n",
      "            : Test Loss :0.5384029150009155 Test Accuracy : 0.9645100235939026 \n",
      "****************************************************************************************************\n",
      "Iteration  404 :Train Loss : 0.50629044  Train Accuracy:  0.9668533\n",
      "            : Test Loss :0.5381823778152466 Test Accuracy : 0.9645500183105469 \n",
      "****************************************************************************************************\n",
      "Iteration  405 :Train Loss : 0.506039  Train Accuracy:  0.966875\n",
      "            : Test Loss :0.5379628539085388 Test Accuracy : 0.9645599722862244 \n",
      "****************************************************************************************************\n",
      "Iteration  406 :Train Loss : 0.5057884  Train Accuracy:  0.9668817\n",
      "            : Test Loss :0.5377441644668579 Test Accuracy : 0.9645699858665466 \n",
      "****************************************************************************************************\n",
      "Iteration  407 :Train Loss : 0.5055389  Train Accuracy:  0.9669\n",
      "            : Test Loss :0.5375263690948486 Test Accuracy : 0.9645900130271912 \n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  408 :Train Loss : 0.50529027  Train Accuracy:  0.966905\n",
      "            : Test Loss :0.5373096466064453 Test Accuracy : 0.9645699858665466 \n",
      "****************************************************************************************************\n",
      "Iteration  409 :Train Loss : 0.50504273  Train Accuracy:  0.9669117\n",
      "            : Test Loss :0.5370937585830688 Test Accuracy : 0.9646099805831909 \n",
      "****************************************************************************************************\n",
      "Iteration  410 :Train Loss : 0.5047961  Train Accuracy:  0.9669333\n",
      "            : Test Loss :0.5368788242340088 Test Accuracy : 0.9646199941635132 \n",
      "****************************************************************************************************\n",
      "Iteration  411 :Train Loss : 0.5045505  Train Accuracy:  0.966945\n",
      "            : Test Loss :0.5366647243499756 Test Accuracy : 0.9646199941635132 \n",
      "****************************************************************************************************\n",
      "Iteration  412 :Train Loss : 0.5043058  Train Accuracy:  0.96697\n",
      "            : Test Loss :0.536451518535614 Test Accuracy : 0.9646199941635132 \n",
      "****************************************************************************************************\n",
      "Iteration  413 :Train Loss : 0.50406194  Train Accuracy:  0.9669833\n",
      "            : Test Loss :0.5362392663955688 Test Accuracy : 0.9646300077438354 \n",
      "****************************************************************************************************\n",
      "Iteration  414 :Train Loss : 0.5038191  Train Accuracy:  0.966995\n",
      "            : Test Loss :0.5360279083251953 Test Accuracy : 0.9646300077438354 \n",
      "****************************************************************************************************\n",
      "Iteration  415 :Train Loss : 0.50357723  Train Accuracy:  0.96700335\n",
      "            : Test Loss :0.5358174443244934 Test Accuracy : 0.9646300077438354 \n",
      "****************************************************************************************************\n",
      "Iteration  416 :Train Loss : 0.50333625  Train Accuracy:  0.96700835\n",
      "            : Test Loss :0.5356078147888184 Test Accuracy : 0.9646499752998352 \n",
      "****************************************************************************************************\n",
      "Iteration  417 :Train Loss : 0.50309616  Train Accuracy:  0.967015\n",
      "            : Test Loss :0.5353989005088806 Test Accuracy : 0.9646300077438354 \n",
      "****************************************************************************************************\n",
      "Iteration  418 :Train Loss : 0.502857  Train Accuracy:  0.96702665\n",
      "            : Test Loss :0.5351909399032593 Test Accuracy : 0.9646400213241577 \n",
      "****************************************************************************************************\n",
      "Iteration  419 :Train Loss : 0.5026188  Train Accuracy:  0.96704\n",
      "            : Test Loss :0.5349839329719543 Test Accuracy : 0.9646599888801575 \n",
      "****************************************************************************************************\n",
      "Iteration  420 :Train Loss : 0.50238144  Train Accuracy:  0.96705836\n",
      "            : Test Loss :0.5347776412963867 Test Accuracy : 0.9646499752998352 \n",
      "****************************************************************************************************\n",
      "Iteration  421 :Train Loss : 0.502145  Train Accuracy:  0.967085\n",
      "            : Test Loss :0.5345722436904907 Test Accuracy : 0.9646499752998352 \n",
      "****************************************************************************************************\n",
      "Iteration  422 :Train Loss : 0.5019095  Train Accuracy:  0.96710336\n",
      "            : Test Loss :0.5343677401542664 Test Accuracy : 0.9646700024604797 \n",
      "****************************************************************************************************\n",
      "Iteration  423 :Train Loss : 0.50167483  Train Accuracy:  0.96713334\n",
      "            : Test Loss :0.5341640710830688 Test Accuracy : 0.9646999835968018 \n",
      "****************************************************************************************************\n",
      "Iteration  424 :Train Loss : 0.501441  Train Accuracy:  0.96715164\n",
      "            : Test Loss :0.5339611768722534 Test Accuracy : 0.9647200107574463 \n",
      "****************************************************************************************************\n",
      "Iteration  425 :Train Loss : 0.5012081  Train Accuracy:  0.9671633\n",
      "            : Test Loss :0.5337592363357544 Test Accuracy : 0.9647300243377686 \n",
      "****************************************************************************************************\n",
      "Iteration  426 :Train Loss : 0.5009761  Train Accuracy:  0.9671767\n",
      "            : Test Loss :0.5335579514503479 Test Accuracy : 0.9647499918937683 \n",
      "****************************************************************************************************\n",
      "Iteration  427 :Train Loss : 0.50074494  Train Accuracy:  0.9671933\n",
      "            : Test Loss :0.5333574414253235 Test Accuracy : 0.9647799730300903 \n",
      "****************************************************************************************************\n",
      "Iteration  428 :Train Loss : 0.50051457  Train Accuracy:  0.967205\n",
      "            : Test Loss :0.5331578850746155 Test Accuracy : 0.9647799730300903 \n",
      "****************************************************************************************************\n",
      "Iteration  429 :Train Loss : 0.50028515  Train Accuracy:  0.96721834\n",
      "            : Test Loss :0.5329591035842896 Test Accuracy : 0.9648000001907349 \n",
      "****************************************************************************************************\n",
      "Iteration  430 :Train Loss : 0.5000565  Train Accuracy:  0.96725\n",
      "            : Test Loss :0.5327610969543457 Test Accuracy : 0.9648000001907349 \n",
      "****************************************************************************************************\n",
      "Iteration  431 :Train Loss : 0.49982876  Train Accuracy:  0.967265\n",
      "            : Test Loss :0.5325638651847839 Test Accuracy : 0.9648299813270569 \n",
      "****************************************************************************************************\n",
      "Iteration  432 :Train Loss : 0.49960178  Train Accuracy:  0.96727836\n",
      "            : Test Loss :0.5323674082756042 Test Accuracy : 0.9648500084877014 \n",
      "****************************************************************************************************\n",
      "Iteration  433 :Train Loss : 0.49937567  Train Accuracy:  0.967305\n",
      "            : Test Loss :0.5321717858314514 Test Accuracy : 0.9648699760437012 \n",
      "****************************************************************************************************\n",
      "Iteration  434 :Train Loss : 0.4991504  Train Accuracy:  0.96732\n",
      "            : Test Loss :0.5319768786430359 Test Accuracy : 0.9648900032043457 \n",
      "****************************************************************************************************\n",
      "Iteration  435 :Train Loss : 0.49892598  Train Accuracy:  0.9673333\n",
      "            : Test Loss :0.5317826867103577 Test Accuracy : 0.9648699760437012 \n",
      "****************************************************************************************************\n",
      "Iteration  436 :Train Loss : 0.49870235  Train Accuracy:  0.967345\n",
      "            : Test Loss :0.5315894484519958 Test Accuracy : 0.9648799896240234 \n",
      "****************************************************************************************************\n",
      "Iteration  437 :Train Loss : 0.49847955  Train Accuracy:  0.967365\n",
      "            : Test Loss :0.5313968658447266 Test Accuracy : 0.9648799896240234 \n",
      "****************************************************************************************************\n",
      "Iteration  438 :Train Loss : 0.49825743  Train Accuracy:  0.96737665\n",
      "            : Test Loss :0.5312050580978394 Test Accuracy : 0.9648799896240234 \n",
      "****************************************************************************************************\n",
      "Iteration  439 :Train Loss : 0.49803627  Train Accuracy:  0.96738666\n",
      "            : Test Loss :0.5310139656066895 Test Accuracy : 0.964900016784668 \n",
      "****************************************************************************************************\n",
      "Iteration  440 :Train Loss : 0.49781582  Train Accuracy:  0.96740836\n",
      "            : Test Loss :0.5308237075805664 Test Accuracy : 0.96492999792099 \n",
      "****************************************************************************************************\n",
      "Iteration  441 :Train Loss : 0.49759623  Train Accuracy:  0.96742165\n",
      "            : Test Loss :0.5306341648101807 Test Accuracy : 0.9649400115013123 \n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  442 :Train Loss : 0.49737734  Train Accuracy:  0.9674417\n",
      "            : Test Loss :0.5304453372955322 Test Accuracy : 0.9649199843406677 \n",
      "****************************************************************************************************\n",
      "Iteration  443 :Train Loss : 0.49715924  Train Accuracy:  0.96746665\n",
      "            : Test Loss :0.5302571654319763 Test Accuracy : 0.96492999792099 \n",
      "****************************************************************************************************\n",
      "Iteration  444 :Train Loss : 0.49694198  Train Accuracy:  0.967475\n",
      "            : Test Loss :0.5300697684288025 Test Accuracy : 0.96492999792099 \n",
      "****************************************************************************************************\n",
      "Iteration  445 :Train Loss : 0.49672553  Train Accuracy:  0.9674967\n",
      "            : Test Loss :0.5298832058906555 Test Accuracy : 0.964959979057312 \n",
      "****************************************************************************************************\n",
      "Iteration  446 :Train Loss : 0.49650982  Train Accuracy:  0.96751165\n",
      "            : Test Loss :0.5296971797943115 Test Accuracy : 0.9649800062179565 \n",
      "****************************************************************************************************\n",
      "Iteration  447 :Train Loss : 0.4962948  Train Accuracy:  0.9675317\n",
      "            : Test Loss :0.5295119881629944 Test Accuracy : 0.9649900197982788 \n",
      "****************************************************************************************************\n",
      "Iteration  448 :Train Loss : 0.49608055  Train Accuracy:  0.9675433\n",
      "            : Test Loss :0.5293275117874146 Test Accuracy : 0.9650200009346008 \n",
      "****************************************************************************************************\n",
      "Iteration  449 :Train Loss : 0.49586704  Train Accuracy:  0.9675583\n",
      "            : Test Loss :0.5291438698768616 Test Accuracy : 0.9650300145149231 \n",
      "****************************************************************************************************\n",
      "Iteration  450 :Train Loss : 0.49565443  Train Accuracy:  0.96756667\n",
      "            : Test Loss :0.5289607644081116 Test Accuracy : 0.9650800228118896 \n",
      "****************************************************************************************************\n",
      "Iteration  451 :Train Loss : 0.49544245  Train Accuracy:  0.96757835\n",
      "            : Test Loss :0.5287784337997437 Test Accuracy : 0.9650899767875671 \n",
      "****************************************************************************************************\n",
      "Iteration  452 :Train Loss : 0.4952312  Train Accuracy:  0.9675933\n",
      "            : Test Loss :0.5285966992378235 Test Accuracy : 0.9650800228118896 \n",
      "****************************************************************************************************\n",
      "Iteration  453 :Train Loss : 0.49502072  Train Accuracy:  0.9676167\n",
      "            : Test Loss :0.5284157395362854 Test Accuracy : 0.9650800228118896 \n",
      "****************************************************************************************************\n",
      "Iteration  454 :Train Loss : 0.49481097  Train Accuracy:  0.96762335\n",
      "            : Test Loss :0.5282352566719055 Test Accuracy : 0.9650700092315674 \n",
      "****************************************************************************************************\n",
      "Iteration  455 :Train Loss : 0.49460196  Train Accuracy:  0.96763164\n",
      "            : Test Loss :0.5280557870864868 Test Accuracy : 0.9650800228118896 \n",
      "****************************************************************************************************\n",
      "Iteration  456 :Train Loss : 0.49439365  Train Accuracy:  0.9676483\n",
      "            : Test Loss :0.5278767347335815 Test Accuracy : 0.9650999903678894 \n",
      "****************************************************************************************************\n",
      "Iteration  457 :Train Loss : 0.49418607  Train Accuracy:  0.967675\n",
      "            : Test Loss :0.5276985168457031 Test Accuracy : 0.9651200175285339 \n",
      "****************************************************************************************************\n",
      "Iteration  458 :Train Loss : 0.49397925  Train Accuracy:  0.96768\n",
      "            : Test Loss :0.5275210738182068 Test Accuracy : 0.9651399850845337 \n",
      "****************************************************************************************************\n",
      "Iteration  459 :Train Loss : 0.49377304  Train Accuracy:  0.96769834\n",
      "            : Test Loss :0.5273440480232239 Test Accuracy : 0.9651399850845337 \n",
      "****************************************************************************************************\n",
      "Iteration  460 :Train Loss : 0.4935676  Train Accuracy:  0.96771\n",
      "            : Test Loss :0.5271677374839783 Test Accuracy : 0.9651299715042114 \n",
      "****************************************************************************************************\n",
      "Iteration  461 :Train Loss : 0.4933628  Train Accuracy:  0.9677167\n",
      "            : Test Loss :0.52699214220047 Test Accuracy : 0.9651200175285339 \n",
      "****************************************************************************************************\n",
      "Iteration  462 :Train Loss : 0.49315885  Train Accuracy:  0.967735\n",
      "            : Test Loss :0.5268172025680542 Test Accuracy : 0.9651299715042114 \n",
      "****************************************************************************************************\n",
      "Iteration  463 :Train Loss : 0.49295554  Train Accuracy:  0.96774167\n",
      "            : Test Loss :0.5266429781913757 Test Accuracy : 0.9651399850845337 \n",
      "****************************************************************************************************\n",
      "Iteration  464 :Train Loss : 0.4927528  Train Accuracy:  0.967755\n",
      "            : Test Loss :0.5264692306518555 Test Accuracy : 0.9651600122451782 \n",
      "****************************************************************************************************\n",
      "Iteration  465 :Train Loss : 0.4925508  Train Accuracy:  0.96776\n",
      "            : Test Loss :0.5262961983680725 Test Accuracy : 0.965149998664856 \n",
      "****************************************************************************************************\n",
      "Iteration  466 :Train Loss : 0.49234954  Train Accuracy:  0.967775\n",
      "            : Test Loss :0.5261239409446716 Test Accuracy : 0.965179979801178 \n",
      "****************************************************************************************************\n",
      "Iteration  467 :Train Loss : 0.49214897  Train Accuracy:  0.96778834\n",
      "            : Test Loss :0.525952160358429 Test Accuracy : 0.9652100205421448 \n",
      "****************************************************************************************************\n",
      "Iteration  468 :Train Loss : 0.49194902  Train Accuracy:  0.96781\n",
      "            : Test Loss :0.5257810354232788 Test Accuracy : 0.9652400016784668 \n",
      "****************************************************************************************************\n",
      "Iteration  469 :Train Loss : 0.4917498  Train Accuracy:  0.967825\n",
      "            : Test Loss :0.525610625743866 Test Accuracy : 0.9652400016784668 \n",
      "****************************************************************************************************\n",
      "Iteration  470 :Train Loss : 0.4915511  Train Accuracy:  0.96784335\n",
      "            : Test Loss :0.5254406929016113 Test Accuracy : 0.9652799963951111 \n",
      "****************************************************************************************************\n",
      "Iteration  471 :Train Loss : 0.4913532  Train Accuracy:  0.9678533\n",
      "            : Test Loss :0.5252715349197388 Test Accuracy : 0.9652900099754333 \n",
      "****************************************************************************************************\n",
      "Iteration  472 :Train Loss : 0.49115598  Train Accuracy:  0.967865\n",
      "            : Test Loss :0.5251028537750244 Test Accuracy : 0.9652900099754333 \n",
      "****************************************************************************************************\n",
      "Iteration  473 :Train Loss : 0.49095938  Train Accuracy:  0.96788836\n",
      "            : Test Loss :0.5249348878860474 Test Accuracy : 0.9653099775314331 \n",
      "****************************************************************************************************\n",
      "Iteration  474 :Train Loss : 0.49076337  Train Accuracy:  0.9678983\n",
      "            : Test Loss :0.5247675776481628 Test Accuracy : 0.9653400182723999 \n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  475 :Train Loss : 0.4905681  Train Accuracy:  0.96791166\n",
      "            : Test Loss :0.5246008634567261 Test Accuracy : 0.9653599858283997 \n",
      "****************************************************************************************************\n",
      "Iteration  476 :Train Loss : 0.49037343  Train Accuracy:  0.9679367\n",
      "            : Test Loss :0.5244346857070923 Test Accuracy : 0.9653599858283997 \n",
      "****************************************************************************************************\n",
      "Iteration  477 :Train Loss : 0.49017948  Train Accuracy:  0.96795666\n",
      "            : Test Loss :0.5242691040039062 Test Accuracy : 0.9653400182723999 \n",
      "****************************************************************************************************\n",
      "Iteration  478 :Train Loss : 0.48998606  Train Accuracy:  0.96797\n",
      "            : Test Loss :0.5241041779518127 Test Accuracy : 0.9653499722480774 \n",
      "****************************************************************************************************\n",
      "Iteration  479 :Train Loss : 0.48979336  Train Accuracy:  0.967975\n",
      "            : Test Loss :0.5239397287368774 Test Accuracy : 0.9653699994087219 \n",
      "****************************************************************************************************\n",
      "Iteration  480 :Train Loss : 0.48960117  Train Accuracy:  0.967985\n",
      "            : Test Loss :0.5237759947776794 Test Accuracy : 0.965399980545044 \n",
      "****************************************************************************************************\n",
      "Iteration  481 :Train Loss : 0.48940974  Train Accuracy:  0.96800166\n",
      "            : Test Loss :0.5236126184463501 Test Accuracy : 0.965399980545044 \n",
      "****************************************************************************************************\n",
      "Iteration  482 :Train Loss : 0.4892188  Train Accuracy:  0.968015\n",
      "            : Test Loss :0.5234501957893372 Test Accuracy : 0.9653900265693665 \n",
      "****************************************************************************************************\n",
      "Iteration  483 :Train Loss : 0.48902863  Train Accuracy:  0.96802336\n",
      "            : Test Loss :0.5232881903648376 Test Accuracy : 0.9653900265693665 \n",
      "****************************************************************************************************\n",
      "Iteration  484 :Train Loss : 0.488839  Train Accuracy:  0.9680383\n",
      "            : Test Loss :0.5231266617774963 Test Accuracy : 0.9653800129890442 \n",
      "****************************************************************************************************\n",
      "Iteration  485 :Train Loss : 0.48864993  Train Accuracy:  0.968045\n",
      "            : Test Loss :0.5229658484458923 Test Accuracy : 0.9653699994087219 \n",
      "****************************************************************************************************\n",
      "Iteration  486 :Train Loss : 0.4884616  Train Accuracy:  0.968055\n",
      "            : Test Loss :0.5228054523468018 Test Accuracy : 0.9654099941253662 \n",
      "****************************************************************************************************\n",
      "Iteration  487 :Train Loss : 0.48827383  Train Accuracy:  0.96805835\n",
      "            : Test Loss :0.5226457715034485 Test Accuracy : 0.9654200077056885 \n",
      "****************************************************************************************************\n",
      "Iteration  488 :Train Loss : 0.48808664  Train Accuracy:  0.9680617\n",
      "            : Test Loss :0.5224865674972534 Test Accuracy : 0.9654399752616882 \n",
      "****************************************************************************************************\n",
      "Iteration  489 :Train Loss : 0.48790008  Train Accuracy:  0.96808\n",
      "            : Test Loss :0.5223278999328613 Test Accuracy : 0.9654399752616882 \n",
      "****************************************************************************************************\n",
      "Iteration  490 :Train Loss : 0.48771405  Train Accuracy:  0.96809167\n",
      "            : Test Loss :0.5221698880195618 Test Accuracy : 0.9654499888420105 \n",
      "****************************************************************************************************\n",
      "Iteration  491 :Train Loss : 0.48752868  Train Accuracy:  0.96810335\n",
      "            : Test Loss :0.5220124125480652 Test Accuracy : 0.9654600024223328 \n",
      "****************************************************************************************************\n",
      "Iteration  492 :Train Loss : 0.48734394  Train Accuracy:  0.9681117\n",
      "            : Test Loss :0.5218554735183716 Test Accuracy : 0.9654499888420105 \n",
      "****************************************************************************************************\n",
      "Iteration  493 :Train Loss : 0.48715973  Train Accuracy:  0.968125\n",
      "            : Test Loss :0.5216988325119019 Test Accuracy : 0.9654399752616882 \n",
      "****************************************************************************************************\n",
      "Iteration  494 :Train Loss : 0.48697603  Train Accuracy:  0.968135\n",
      "            : Test Loss :0.5215432643890381 Test Accuracy : 0.965470016002655 \n",
      "****************************************************************************************************\n",
      "Iteration  495 :Train Loss : 0.48679298  Train Accuracy:  0.9681517\n",
      "            : Test Loss :0.5213878750801086 Test Accuracy : 0.9654600024223328 \n",
      "****************************************************************************************************\n",
      "Iteration  496 :Train Loss : 0.48661062  Train Accuracy:  0.968155\n",
      "            : Test Loss :0.5212331414222717 Test Accuracy : 0.9654399752616882 \n",
      "****************************************************************************************************\n",
      "Iteration  497 :Train Loss : 0.48642865  Train Accuracy:  0.96817166\n",
      "            : Test Loss :0.521078884601593 Test Accuracy : 0.9654399752616882 \n",
      "****************************************************************************************************\n",
      "Iteration  498 :Train Loss : 0.4862474  Train Accuracy:  0.96817\n",
      "            : Test Loss :0.5209252238273621 Test Accuracy : 0.9654399752616882 \n",
      "****************************************************************************************************\n",
      "Iteration  499 :Train Loss : 0.4860666  Train Accuracy:  0.968175\n",
      "            : Test Loss :0.5207719206809998 Test Accuracy : 0.9654499888420105 \n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "    # load the training and test data    \n",
    "    (tr_x, tr_y), (te_x, te_y) = fashion_mnist.load_data()\n",
    "\n",
    "    \"\"\"reshape the feature data\"\"\"\n",
    "    tr_x = tr_x.reshape(tr_x.shape[0], 784)\n",
    "    te_x = te_x.reshape(te_x.shape[0], 784)\n",
    "\n",
    "    \"\"\"noramlise feature data\"\"\"\n",
    "    tr_x = tr_x / 255.0\n",
    "    te_x = te_x / 255.0\n",
    "\n",
    "\n",
    "    \"\"\" one hot encode the training labels and get the transpose\"\"\"\n",
    "    tr_y = np_utils.to_categorical(tr_y,10)\n",
    "    tr_y = tr_y.T\n",
    "\n",
    "\n",
    "    \"\"\"one hot encode the test labels and get the transpose\"\"\"\n",
    "    te_y = np_utils.to_categorical(te_y,10)\n",
    "    te_y = te_y.T\n",
    "\n",
    "    return tr_x, tr_y, te_x, te_y\n",
    "     \n",
    "    \n",
    "\n",
    "\n",
    "def softmax(y_pred):\n",
    "    \"\"\"Compute softmax values for each of the image in X .\n",
    "       And convert each predicted value into a probability betwen 0 and 1, summing to 1 \n",
    "    \"\"\"\n",
    "    return tf.exp(y_pred) / tf.reduce_sum(tf.exp(y_pred), axis=0) \n",
    "\n",
    "def forward_pass(x, w_T, b):    \n",
    "    \n",
    "    '''Taking the transpose to allow matrix multiplication  (60,000 * 784) ==> (784 * 60,000)'''\n",
    "    x = tf.transpose(x)\n",
    "    \n",
    "    \"\"\" We need to mutliply each training example by the weights and add bias\"\"\"\n",
    "    y_pred = tf.matmul(w_T, x) + b   \n",
    "    \n",
    "    \"\"\"Pipe the results through the softmax activation function. \"\"\"\n",
    "    y_pred_softmax = softmax(y_pred)\n",
    "\n",
    "    \n",
    "    return y_pred_softmax\n",
    "\n",
    "\n",
    "\n",
    "def cross_entropy(y, y_pred):\n",
    "    '''Sometimes the softmax  values (probability) ouptutted by a neuron can se very very close to 0 or 0\n",
    "       In this case the log(0)==> not defined and will result in NaN values.\n",
    "       This can be handled using this function clip_by_value which replaces every value less than threshold\n",
    "       with the minimum value (1e-10)'''\n",
    "    \n",
    "    y_pred_ = tf.clip_by_value(y_pred, 1e-10, 1.0)\n",
    " \n",
    "    \"\"\"Calculate the crosss entropy loss per image\"\"\"\n",
    "    loss_per_image = - tf.reduce_sum( y * tf.math.log(y_pred), axis=0 )\n",
    "    \n",
    "    \"\"\"Calculate the average loss\"\"\"\n",
    "    average_loss = tf.reduce_mean(loss_per_image)\n",
    "\n",
    "    \n",
    "    return average_loss\n",
    "       \n",
    "    \n",
    "\n",
    "def calculate_accuracy(x, y, w, b):\n",
    "    '''Pass the given input through the network'''\n",
    "    y_pred_softmax = forward_pass(x, w, b)\n",
    "    \n",
    "    \"\"\"Round the predictions to the nearest integer to either 1. or 0.\"\"\"\n",
    "    predictions = tf.round(y_pred_softmax)\n",
    "    \n",
    "    \"\"\" tf.equal will return a boolean array: True if prediction correct, False otherwise\n",
    "        tf.cast converts the resulting boolean array to a numerical array \n",
    "        1 if True (correct prediction), 0 if False (incorrect prediction)\"\"\"\n",
    "    predictions_correct = tf.cast(tf.equal(predictions, y), tf.float32)\n",
    "\n",
    "    \"\"\"Finally, we just determine the mean value of predictions_correct\"\"\"\n",
    "    accuracy = tf.reduce_mean(predictions_correct)\n",
    "    \n",
    "\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def main():\n",
    "    list_of_test_accuracies=[]\n",
    "    list_of_train_accuracies=[]\n",
    "    list_of_test_loss=[]\n",
    "    list_of_train_loss=[]\n",
    "    \n",
    "    learning_rate = 0.01\n",
    "    num_Iterations = 500\n",
    "    adam_optimizer = tf.keras.optimizers.Adam()\n",
    "    \n",
    "    '''Load Data'''\n",
    "    tr_x, tr_y, te_x, te_y  = load_data()\n",
    "    \n",
    "    '''Cast the input values in a compatible tensorflow float32 format'''\n",
    "    tr_x = tf.cast(tr_x, tf.float32)\n",
    "    te_x = tf.cast(te_x, tf.float32)\n",
    "    tr_y = tf.cast(tr_y, tf.float32)\n",
    "    te_y = tf.cast(te_y, tf.float32)\n",
    "    \n",
    "\n",
    "    \"\"\"We need a coefficient for each of the features and a single bias value\"\"\"\n",
    "    w = tf.Variable(tf.random.normal([ 10,tr_x.shape[1]], mean=0.0, stddev=0.05))\n",
    "    \n",
    "    print('w shape ==>',w.shape)\n",
    "    print('tr_x shape ==>',tr_x.shape)\n",
    "    \n",
    "    b = tf.Variable([0.])\n",
    "   \n",
    "    \"\"\"Iterate our training loop\"\"\"   \n",
    "    \n",
    "    \"\"\"Create an instance of GradientTape to monitor the forward pass \n",
    "    and calcualte the gradients for each of the variables m and c\"\"\"\n",
    "    for i in range(num_Iterations):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = forward_pass(tr_x, w, b)    \n",
    "            currentLoss = cross_entropy(tr_y, y_pred)\n",
    "            list_of_train_loss.append(currentLoss.numpy())\n",
    "            \n",
    "        \"\"\"Calculate partial derivatives of Average Loss with respect to change in w and b\"\"\"\n",
    "        gradients = tape.gradient(currentLoss, [w, b])\n",
    "        accuracy = calculate_accuracy(tr_x, tr_y, w, b)\n",
    "        \n",
    "        \"\"\"Append for plotting\"\"\"\n",
    "        list_of_train_accuracies.append(accuracy.numpy())\n",
    "        \n",
    "        \n",
    "        print (\"Iteration \", i, \":Train Loss :\",currentLoss.numpy(), \" Train Accuracy: \", accuracy.numpy())\n",
    "        \n",
    "        \n",
    "        \"\"\"Give the above calculated derivatives to the optimizer to decent to the most optimal path\"\"\"\n",
    "        adam_optimizer.apply_gradients(zip(gradients, [w,b]))\n",
    "        \n",
    "        \"\"\"Lets see how the model performs with the newly upadted w and b on the test data\"\"\"\n",
    "        te_y_pred = forward_pass(te_x, w, b)\n",
    "        current_Test_Loss = cross_entropy(te_y, te_y_pred)\n",
    "        list_of_test_loss.append(current_Test_Loss.numpy())\n",
    "\n",
    "        test_accuracy = calculate_accuracy(te_x, te_y, w, b) \n",
    "        list_of_test_accuracies.append(test_accuracy.numpy())\n",
    "\n",
    "        print (\"            : Test Loss :{0} Test Accuracy : {1} \" .format(current_Test_Loss,test_accuracy) )\n",
    "        \n",
    "        print(\"*\"*100)\n",
    "        \n",
    "        \n",
    "    \"\"\"Plotting the performance\"\"\"\n",
    "    configuration = 'Basic Network with 10 softmax neurons'\n",
    "#     configuration = '300 ReLu 100 Relu, 10 softmax neurons'\n",
    "    plt.title(\"Training vs Validation Loss \\n\"+configuration+' Epochs:'+str (num_Iterations))\n",
    "    plt.plot(list_of_test_loss, label=\"Val Loss\")\n",
    "    plt.plot(list_of_train_loss, label=\"Train Loss\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "main()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "id": "dSsq-rmLyNI2",
    "outputId": "78d96127-5d1c-4137-ff43-490b5bd3814b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "numN = np.array([1., 2., 3.])\n",
    "numT = tf.constant(numN)\n",
    "\n",
    "print (numN)\n",
    "print (numT)\n",
    "\n",
    "print (tf.square(numN))\n",
    "print (np.square(numT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of BinaryLogisticRegression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
